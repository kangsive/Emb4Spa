{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dingkang/envs/nlp_a4/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionWiseFFN(nn.Module):\n",
    "    \"\"\"Same MLP applied to all token(position) representations\"\"\"\n",
    "    def __init__(self, emb_dim, ffn_dim):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(emb_dim, ffn_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(ffn_dim, emb_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.fc2(self.relu(self.fc1(x)))\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, emb_dim, max_seq_len):\n",
    "        super().__init__()\n",
    "\n",
    "        pe = torch.zeros(max_seq_len, emb_dim)\n",
    "        position = torch.arange(0, max_seq_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, emb_dim, 2).float() * -(math.log(10000.0) / emb_dim))\n",
    "\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "        self.register_buffer('pe', pe.unsqueeze(0))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:, :x.size(1)]\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, emb_dim, num_heads):\n",
    "        super().__init__()\n",
    "        assert emb_dim % num_heads == 0, \"Embedding dimension must be divided by number of heads\"\n",
    "\n",
    "        # Dimensions initialization\n",
    "        self.emb_dim = emb_dim\n",
    "        self.num_heads = num_heads\n",
    "        # all features are divided into multi head, each head have a part of features\n",
    "        self.head_emb_dim = self.emb_dim // self.num_heads\n",
    "\n",
    "        # Transformation matrixs\n",
    "        self.W_q = nn.Linear(emb_dim, emb_dim)\n",
    "        self.W_k = nn.Linear(emb_dim, emb_dim)\n",
    "        self.W_v = nn.Linear(emb_dim, emb_dim)\n",
    "        self.W_o = nn.Linear(emb_dim, emb_dim)\n",
    "\n",
    "    def scaled_dot_product_attention(self, Q, K, V, mask=None):\n",
    "        # Calculate attention scores\n",
    "        attn_scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.head_emb_dim)\n",
    "\n",
    "        # Mask scores (where positions are 0) with near negative inf\n",
    "        if mask is not None:\n",
    "            attn_scores = attn_scores.masked_fill(mask == 0, -1e9)\n",
    "\n",
    "        # Apply sofxmax to attention scores\n",
    "        attn_scores = torch.softmax(attn_scores, dim=-1)\n",
    "\n",
    "        # Get the final output\n",
    "        output = torch.matmul(attn_scores, V)\n",
    "        return output\n",
    "    \n",
    "    def split(self, x):\n",
    "        # Reshape the input emb_dim (to multi-head, each head owns a part of input features) for multi-head attention\n",
    "        batch_size, seq_len, emb_dim = x.size()\n",
    "        # transpose to fix batch_size and num_heads, let seq_len, head_emb_dim participate in matrix multiplication\n",
    "        return x.view(batch_size, seq_len, self.num_heads, self.head_emb_dim).transpose(1, 2)\n",
    "\n",
    "    def combine(self, x):\n",
    "        batch_size, num_heads, seq_len, head_emb_dim = x.size()\n",
    "        # contiguous() ensures the memory layout of the tensor is contiguous\n",
    "        return x.transpose(1, 2).contiguous().view(batch_size, seq_len, self.emb_dim)\n",
    "    \n",
    "    def forward(self, Q, K, V, mask=None):\n",
    "        # Split input to multi heads\n",
    "        Q = self.split(self.W_q(Q))\n",
    "        K = self.split(self.W_k(K))\n",
    "        V = self.split(self.W_v(V))\n",
    "\n",
    "        # Perform scaled dot-product attention\n",
    "        attn_output = self.scaled_dot_product_attention(Q, K, V, mask)\n",
    "\n",
    "        # Combine outputs and apply transformation\n",
    "        output = self.W_o(self.combine(attn_output))\n",
    "        return output\n",
    "    \n",
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, emb_dim, num_heads, ffn_dim, dropout):\n",
    "        super().__init__()\n",
    "        self.self_atten = MultiHeadAttention(emb_dim, num_heads)\n",
    "        self.ffn = PositionWiseFFN(emb_dim, ffn_dim)\n",
    "        self.norm1 = nn.LayerNorm(emb_dim)\n",
    "        self.norm2 = nn.LayerNorm(emb_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        attn_output = self.self_atten(x, x, x, mask)\n",
    "        x = self.norm1(x + self.dropout(attn_output))\n",
    "        ffn_output = self.ffn(x)\n",
    "        x = self.norm2(x + self.dropout(ffn_output))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolygonEncoder(nn.Module):\n",
    "    def __init__(self, emb_dim, num_heads,\n",
    "                num_layers, ffn_dim, max_seq_len, dropout):\n",
    "        super().__init__()\n",
    "        self.encoder_layers = nn.ModuleList([EncoderLayer(emb_dim, num_heads, ffn_dim, dropout) for _ in range(num_layers)])\n",
    "        self.class_embedding = nn.Parameter(torch.randn(1, 1, emb_dim))\n",
    "        self.pos_embedding = nn.Parameter(torch.randn(1, 1 + max_seq_len, emb_dim))\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        # token_mask = (tokens != 0).unsqueeze(1).unsqueeze(2)\n",
    "        batch_size, seq_len, emb_dim = x.shape\n",
    "        class_embedding = self.class_embedding.repeat(batch_size, 1, 1)\n",
    "        x = torch.cat([class_embedding, x], dim=1)\n",
    "        # print(x.shape, self.pos_embedding[:, :seq_len+1].shape)\n",
    "        x = x + self.pos_embedding[:, :seq_len+1]\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # Create a new tensor with True values in the first column (for cls token)\n",
    "        if mask is not None:\n",
    "            cls_mask = torch.ones((batch_size, 1, 1, 1), dtype=torch.bool).to(device)\n",
    "            mask = torch.cat((cls_mask, mask), dim=3)\n",
    "        \n",
    "        for enc_layer in self.encoder_layers:\n",
    "            x = enc_layer(x, mask)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "class PolygonTransformer(nn.Module):\n",
    "    def __init__(self, num_types, emb_dim, num_heads, num_layers, ffn_dim, max_seq_len, dropout):\n",
    "        super().__init__()\n",
    "        self.encoder = PolygonEncoder(emb_dim, num_heads, num_layers, ffn_dim, max_seq_len, dropout)\n",
    "        self.mlp_head = nn.Sequential(nn.Linear(emb_dim, ffn_dim),\n",
    "                                      nn.ReLU(),\n",
    "                                      nn.Linear(ffn_dim, num_types))\n",
    "        \n",
    "    def forward(self, x, mask=None):\n",
    "        x = self.encoder(x, mask)\n",
    "        x = x[:, 0, :] # grab the class embedding\n",
    "        x = self.mlp_head(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class CompareModel(nn.Module):\n",
    "    def __init__(self, emb_dim, dense_size, dropout, output_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Define the layers\n",
    "        self.conv1 = nn.Conv1d(emb_dim, 32, kernel_size=5, padding=2)  # Assuming input channels=1\n",
    "        self.conv2 = nn.Conv1d(32, 64, kernel_size=5, padding=2)\n",
    "        self.maxpool = nn.MaxPool1d(kernel_size=3)\n",
    "        self.global_avgpool = nn.AdaptiveAvgPool1d(1)  # Global average pooling\n",
    "        self.dense1 = nn.Linear(64, dense_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.dense2 = nn.Linear(dense_size, output_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Input shape: (batch_size, seq_len, geom_vector_len)\n",
    "        # Convolutional layers\n",
    "        x = x.permute(0, 2, 1)  # Permute to (batch_size, channels, seq_len)\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.global_avgpool(x)\n",
    "        \n",
    "        # Flatten\n",
    "        x = x.view(x.size(0), -1)  # Reshape to (batch_size, num_features)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        x = self.dense1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.dense2(x)\n",
    "\n",
    "        # No need to add softmax (already included in CrossEntropyLossFunction), otherwise it will be double softmax and converge slower\n",
    "\n",
    "        return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid wkt string, skip it\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from deep_geometry import vectorizer as gv\n",
    "from deep_geometry import GeomScaler\n",
    "\n",
    "\n",
    "max_seq_len = 64\n",
    "batch_size = 32\n",
    "\n",
    "\n",
    "gs = GeomScaler()\n",
    "types_dict = {'PK':0, 'MR': 1, 'KL':2, 'NV':3, 'WA':4, 'LG':5, 'HO':6, 'GR':7, 'REC':8, 'PGK':9}\n",
    "df = pd.read_csv(\"archaeology.csv\")\n",
    "df['type'] = df['Aardspoor'].map(types_dict)\n",
    "df = df.dropna().reset_index(drop=True)\n",
    "\n",
    "def count_points(wkt):\n",
    "    try:\n",
    "        num_points = gv.num_points_from_wkt(wkt)\n",
    "        return num_points\n",
    "    except:\n",
    "        print(\"Invalid wkt string, skip it\")\n",
    "        return np.inf\n",
    "\n",
    "filtered_df = df[df['WKT'].apply(lambda x: count_points(x) <= max_seq_len)]\n",
    "df = filtered_df\n",
    "\n",
    "df = df[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_split(df, val_split_ratio, test_split_ratio):\n",
    "\n",
    "    data, labels = np.array(df['WKT'].tolist()), np.array(df['type'].tolist())\n",
    "\n",
    "    num_val = int(val_split_ratio * len(df))\n",
    "    num_test = int(test_split_ratio * len(df))\n",
    "\n",
    "    indices = np.arange(len(df))\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "    train_indices, val_indices, test_indices = indices[num_val+num_test:], indices[:num_val], indices[num_val:num_val+num_test]\n",
    "\n",
    "    train_data, train_labels = data[train_indices], labels[train_indices]\n",
    "    val_data, val_labels = data[val_indices], labels[val_indices]\n",
    "    test_data, test_labels = data[test_indices], labels[test_indices]\n",
    "\n",
    "    return train_data, train_labels, val_data, val_labels, test_data, test_labels\n",
    "\n",
    "ori_train_data, ori_train_labels, ori_val_data, ori_val_labels, ori_test_data, ori_test_labels = dataset_split(df, 0.1, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_polygon_dataset(wkts, types, max_seq_len): # TODO - 1. split into train, validate, test. 2. randomly sample\n",
    "    geoms, labels, start_points = [], [], []\n",
    "    for i, wkt in enumerate(wkts):\n",
    "        num_point = gv.num_points_from_wkt(wkt)\n",
    "        if  num_point > max_seq_len:\n",
    "             continue\n",
    "        geom = gv.vectorize_wkt(wkt, max_points=max_seq_len, fixed_size=True)\n",
    "        geoms.append(geom)\n",
    "        labels.append(types[i])\n",
    "        start_points.append(num_point)\n",
    "\n",
    "    start_points = torch.tensor(start_points).unsqueeze(1)\n",
    "    indices = torch.arange(max_seq_len).unsqueeze(0)\n",
    "    mask = indices < start_points\n",
    "    mask = mask.unsqueeze(1).unsqueeze(2)\n",
    "    tokens = np.stack(geoms, axis=0)\n",
    "    gs.fit(tokens)\n",
    "    tokens = gs.transform(tokens)\n",
    "    tokens = torch.tensor(tokens, dtype=torch.float32)\n",
    "    labels = torch.tensor(labels, dtype=torch.long)\n",
    "    \n",
    "    return tokens, labels, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your custom dataset\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tokens, train_labels, train_mask = prepare_polygon_dataset(ori_train_data, ori_train_labels, max_seq_len)\n",
    "val_tokens, val_labels, val_mask = prepare_polygon_dataset(ori_val_data, ori_val_labels, max_seq_len)\n",
    "test_tokens, test_labels, test_mask = prepare_polygon_dataset(ori_test_data, ori_test_labels, max_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_split_ratio, test_split_ratio = 0.1, 0.2\n",
    "# train_dataset, val_dataset, test_dataset = random_split(dataset, [0.7, 0.1, 0.2])\n",
    "\n",
    "train_loader = DataLoader(TensorDataset(train_tokens, train_labels, train_mask), batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(TensorDataset(val_tokens, val_labels, val_mask), batch_size=batch_size)\n",
    "test_loader = DataLoader(TensorDataset(test_tokens, test_labels, test_mask), batch_size=batch_size)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Train Loss: 1.9073412743481724, Val Loss: 1.6210010647773743, Val Acc: 0.57\n",
      "Epoch: 2, Train Loss: 1.5043791749260642, Val Loss: 1.4942034482955933, Val Acc: 0.57\n",
      "Epoch: 3, Train Loss: 1.3994573734023354, Val Loss: 1.4798990488052368, Val Acc: 0.57\n",
      "Epoch: 4, Train Loss: 1.3711142431605945, Val Loss: 1.457416981458664, Val Acc: 0.57\n",
      "Epoch: 5, Train Loss: 1.362732307477431, Val Loss: 1.453051209449768, Val Acc: 0.57\n",
      "Epoch: 6, Train Loss: 1.357334630055861, Val Loss: 1.4269547760486603, Val Acc: 0.57\n",
      "Epoch: 7, Train Loss: 1.3497822826558894, Val Loss: 1.4270367920398712, Val Acc: 0.57\n",
      "Epoch: 8, Train Loss: 1.3507517522031611, Val Loss: 1.425373613834381, Val Acc: 0.57\n",
      "Epoch: 9, Train Loss: 1.3483836271546104, Val Loss: 1.4310104548931122, Val Acc: 0.57\n",
      "Epoch: 10, Train Loss: 1.3431221138347278, Val Loss: 1.4185477495193481, Val Acc: 0.57\n",
      "Epoch: 11, Train Loss: 1.3429289785298435, Val Loss: 1.4106917083263397, Val Acc: 0.57\n",
      "Epoch: 12, Train Loss: 1.3369650840759277, Val Loss: 1.4007059633731842, Val Acc: 0.57\n",
      "Epoch: 13, Train Loss: 1.3241904269565234, Val Loss: 1.3758257925510406, Val Acc: 0.57\n",
      "Epoch: 14, Train Loss: 1.3120836154981093, Val Loss: 1.3435673862695694, Val Acc: 0.57\n",
      "Epoch: 15, Train Loss: 1.286983853036707, Val Loss: 1.3159439712762833, Val Acc: 0.58\n",
      "Epoch: 16, Train Loss: 1.2853152751922607, Val Loss: 1.3103352934122086, Val Acc: 0.63\n",
      "Epoch: 17, Train Loss: 1.2610275962136008, Val Loss: 1.3114927262067795, Val Acc: 0.64\n",
      "Epoch: 18, Train Loss: 1.2418701621619137, Val Loss: 1.3201926946640015, Val Acc: 0.64\n",
      "Epoch: 19, Train Loss: 1.2232648459347812, Val Loss: 1.307193323969841, Val Acc: 0.64\n",
      "Epoch: 20, Train Loss: 1.261254925619472, Val Loss: 1.301027625799179, Val Acc: 0.65\n",
      "Test Loss: 1.1053003583635603, Test Acc: 0.625\n"
     ]
    }
   ],
   "source": [
    "pot = PolygonTransformer(num_types=10,\n",
    "                        emb_dim=7,\n",
    "                        num_heads=1,\n",
    "                        num_layers=3,\n",
    "                        ffn_dim=64, \n",
    "                        max_seq_len=max_seq_len,\n",
    "                        dropout=0.5)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(pot.parameters(), lr=0.001, betas=(0.9, 0.98), eps=1e-9)\n",
    "\n",
    "num_epochs = 20\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    pot.train()\n",
    "    train_loss = 0.0\n",
    "    for batch_x, batch_y, batch_mask in train_loader:\n",
    "        batch_x, batch_y, batch_mask = batch_x.to(device), batch_y.to(device), batch_mask.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = pot(batch_x, batch_mask)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    pot.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_x, batch_y, batch_mask in val_loader:\n",
    "            batch_x, batch_y, batch_mask = batch_x.to(device), batch_y.to(device), batch_mask.to(device)\n",
    "            outputs = pot(batch_x, batch_mask)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += batch_y.size(0)\n",
    "            correct += (predicted == batch_y).sum().item()\n",
    "    val_loss /= len(val_loader)\n",
    "    val_acc = correct / total\n",
    "    print(f\"Epoch: {epoch+1}, Train Loss: {train_loss/len(train_loader)}, Val Loss: {val_loss}, Val Acc: {val_acc}\")\n",
    "\n",
    "\n",
    "# Test\n",
    "pot.eval()\n",
    "test_loss = 0.0\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for batch_x, batch_y, batch_mask in test_loader:\n",
    "        batch_x, batch_y, batch_mask = batch_x.to(device), batch_y.to(device), batch_mask.to(device)\n",
    "        outputs = pot(batch_x, batch_mask)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        test_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += batch_y.size(0)\n",
    "        correct += (predicted == batch_y).sum().item()\n",
    "test_loss /= len(test_loader)\n",
    "test_acc = correct / total\n",
    "print(f\"Test Loss: {test_loss}, Test Acc: {test_acc}\")\n",
    "\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Conv\n",
    "##### refer to https://arxiv.org/pdf/1806.03857.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(wkts, types):\n",
    "    train_geoms = [gv.vectorize_wkt(wkt) for wkt in wkts]\n",
    "    \n",
    "    zipped = zip(train_geoms, types)\n",
    "    train_input_sorted = {}\n",
    "    train_labels_sorted = {}\n",
    "\n",
    "    for geom, label in sorted(zipped, key=lambda x: len(x[0]), reverse=True):\n",
    "        seq_len = geom.shape[0]\n",
    "        if seq_len in train_input_sorted:\n",
    "            train_input_sorted[seq_len].append(geom)\n",
    "            train_labels_sorted[seq_len].append(label)\n",
    "        else:\n",
    "            train_input_sorted[seq_len] = [geom]\n",
    "            train_labels_sorted[seq_len] = [label]\n",
    "    \n",
    "    return train_input_sorted, train_labels_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_sorted, train_labels_sorted = prepare_dataset(ori_train_data, ori_train_labels)\n",
    "val_input_sorted, val_labels_sorted = prepare_dataset(ori_val_data, ori_val_labels)\n",
    "test_input_sorted, test_labels_sorted = prepare_dataset(ori_test_data, ori_test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_456394/4159577400.py:22: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  inputs = torch.tensor(train_input_sorted[seq_len], dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Train Loss: 1.7568874460245882, Val Loss: 1.7431108048983983, Val Acc: 0.57\n",
      "Epoch: 2, Train Loss: 1.8315633440774584, Val Loss: 1.480326327255794, Val Acc: 0.57\n",
      "Epoch: 3, Train Loss: 1.6594277071574377, Val Loss: 1.4110818326473236, Val Acc: 0.57\n",
      "Epoch: 4, Train Loss: 1.592458915142786, Val Loss: 1.3925866969994136, Val Acc: 0.57\n",
      "Epoch: 5, Train Loss: 1.4769629656322418, Val Loss: 1.3637228731598172, Val Acc: 0.57\n",
      "Epoch: 6, Train Loss: 1.4584554254062592, Val Loss: 1.3256951293775014, Val Acc: 0.57\n",
      "Epoch: 7, Train Loss: 1.409654146149045, Val Loss: 1.32930477474417, Val Acc: 0.57\n",
      "Epoch: 8, Train Loss: 1.329162864931046, Val Loss: 1.3992993329252517, Val Acc: 0.57\n",
      "Epoch: 9, Train Loss: 1.3306236579304649, Val Loss: 1.2731047076838358, Val Acc: 0.63\n",
      "Epoch: 10, Train Loss: 1.2663685021892426, Val Loss: 1.2467984991414207, Val Acc: 0.63\n",
      "Epoch: 11, Train Loss: 1.268877767381214, Val Loss: 1.2466001553194863, Val Acc: 0.63\n",
      "Epoch: 12, Train Loss: 1.2206146262940907, Val Loss: 1.2363242357969284, Val Acc: 0.63\n",
      "Epoch: 13, Train Loss: 1.1873577807157758, Val Loss: 1.2535372027329037, Val Acc: 0.65\n",
      "Epoch: 14, Train Loss: 1.1807855251762602, Val Loss: 1.2578437768987247, Val Acc: 0.64\n",
      "Epoch: 15, Train Loss: 1.1813243625182954, Val Loss: 1.2587672440069062, Val Acc: 0.63\n",
      "Epoch: 16, Train Loss: 1.1663984533340213, Val Loss: 1.2715152470128877, Val Acc: 0.64\n",
      "Epoch: 17, Train Loss: 1.1746314174480854, Val Loss: 1.338616344439132, Val Acc: 0.63\n",
      "Epoch: 18, Train Loss: 1.197186248761321, Val Loss: 1.2983362127095461, Val Acc: 0.63\n",
      "Epoch: 19, Train Loss: 1.1713785627886417, Val Loss: 1.2729695937463215, Val Acc: 0.64\n",
      "Epoch: 20, Train Loss: 1.1332580035049764, Val Loss: 1.2710612556764058, Val Acc: 0.64\n",
      "Test Loss: 1.221730032004416, Test Acc: 0.44333333333333336\n"
     ]
    }
   ],
   "source": [
    "# Create training data\n",
    "sequence_length = 10\n",
    "geom_vector_len = 7  # Assuming geom_vector_len is known\n",
    "dense_size = 64  # Size of the dense layer\n",
    "dropout = 0.5  # Dropout rate\n",
    "num_classes = 10  # Number of output classes\n",
    "batch_size = 32\n",
    "\n",
    "# Define the model, loss function, and optimizer\n",
    "conv_model = CompareModel(emb_dim=geom_vector_len, dense_size=dense_size, dropout=dropout, output_size=num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(conv_model.parameters(), lr=0.001, betas=(0.9, 0.98), eps=1e-9)\n",
    "\n",
    "# Training process\n",
    "num_epochs = 20\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    conv_model.train()\n",
    "    train_loss = 0.0\n",
    "    total_batch_train = 0\n",
    "    for seq_len in train_input_sorted:\n",
    "        inputs = torch.tensor(train_input_sorted[seq_len], dtype=torch.float32)\n",
    "        labels = torch.tensor(train_labels_sorted[seq_len], dtype=torch.long)\n",
    "        dataset = TensorDataset(inputs, labels)\n",
    "        loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "        for batch_x, batch_y in loader:\n",
    "            batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = conv_model(batch_x)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "            total_batch_train += 1\n",
    "\n",
    "    conv_model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    total_batch_val = 0\n",
    "    with torch.no_grad():\n",
    "        for seq_len in val_input_sorted:\n",
    "            inputs = torch.tensor(val_input_sorted[seq_len], dtype=torch.float32)\n",
    "            labels = torch.tensor(val_labels_sorted[seq_len], dtype=torch.long)\n",
    "            dataset = TensorDataset(inputs, labels)\n",
    "            loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "            for batch_x, batch_y in loader:\n",
    "                batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "                outputs = conv_model(batch_x)\n",
    "                loss = criterion(outputs, batch_y)\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total += batch_y.size(0)\n",
    "                total_batch_val += 1\n",
    "                correct += (predicted == batch_y).sum().item()\n",
    "    val_loss /= total_batch_val\n",
    "    val_acc = correct / total\n",
    "    print(f\"Epoch: {epoch+1}, Train Loss: {train_loss/total_batch_train}, Val Loss: {val_loss}, Val Acc: {val_acc}\")\n",
    "\n",
    "# Test\n",
    "conv_model.eval()\n",
    "test_loss = 0.0\n",
    "correct = 0\n",
    "total_batch_test = 0\n",
    "with torch.no_grad():\n",
    "    for seq_len in test_input_sorted:\n",
    "        inputs = torch.tensor(test_input_sorted[seq_len], dtype=torch.float32)\n",
    "        labels = torch.tensor(test_labels_sorted[seq_len], dtype=torch.long)\n",
    "        dataset = TensorDataset(inputs, labels)\n",
    "        loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "        for batch_x, batch_y in loader:\n",
    "            batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "            outputs = conv_model(batch_x)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += batch_y.size(0)\n",
    "            total_batch_test += 1\n",
    "            correct += (predicted == batch_y).sum().item()\n",
    "test_loss /= total_batch_test\n",
    "test_acc = correct / total\n",
    "print(f\"Test Loss: {test_loss}, Test Acc: {test_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters in the Conv model: 16266\n",
      "Total number of parameters in the Transformer model: 5281\n"
     ]
    }
   ],
   "source": [
    "# Count the number of parameters\n",
    "total_params_conv_model = sum(p.numel() for p in conv_model.parameters())\n",
    "print(f\"Total number of parameters in the Conv model: {total_params_conv_model}\")\n",
    "\n",
    "total_params_pot_model = sum(p.numel() for p in pot.parameters())\n",
    "print(f\"Total number of parameters in the Transformer model: {total_params_pot_model}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_a4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

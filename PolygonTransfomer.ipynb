{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dingkang/envs/nlp_a4/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader, random_split"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionWiseFFN(nn.Module):\n",
    "    \"\"\"Same MLP applied to all token(position) representations\"\"\"\n",
    "    def __init__(self, emb_dim, ffn_dim):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(emb_dim, ffn_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(ffn_dim, emb_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.fc2(self.relu(self.fc1(x)))\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, emb_dim, max_seq_len):\n",
    "        super().__init__()\n",
    "\n",
    "        pe = torch.zeros(max_seq_len, emb_dim)\n",
    "        position = torch.arange(0, max_seq_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, emb_dim, 2).float() * -(math.log(10000.0) / emb_dim))\n",
    "\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "        self.register_buffer('pe', pe.unsqueeze(0))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:, :x.size(1)]\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, emb_dim, num_heads):\n",
    "        super().__init__()\n",
    "        assert emb_dim % num_heads == 0, \"Embedding dimension must be divided by number of heads\"\n",
    "\n",
    "        # Dimensions initialization\n",
    "        self.emb_dim = emb_dim\n",
    "        self.num_heads = num_heads\n",
    "        # all features are divided into multi head, each head have a part of features\n",
    "        self.head_emb_dim = self.emb_dim // self.num_heads\n",
    "\n",
    "        # Transformation matrixs\n",
    "        self.W_q = nn.Linear(emb_dim, emb_dim)\n",
    "        self.W_k = nn.Linear(emb_dim, emb_dim)\n",
    "        self.W_v = nn.Linear(emb_dim, emb_dim)\n",
    "        self.W_o = nn.Linear(emb_dim, emb_dim)\n",
    "\n",
    "    def scaled_dot_product_attention(self, Q, K, V, mask=None):\n",
    "        # Calculate attention scores\n",
    "        attn_scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.head_emb_dim)\n",
    "\n",
    "        # Mask scores (where positions are 0) with near negative inf\n",
    "        if mask is not None:\n",
    "            attn_scores = attn_scores.masked_fill(mask == 0, -1e9)\n",
    "\n",
    "        # Apply sofxmax to attention scores\n",
    "        attn_scores = torch.softmax(attn_scores, dim=-1)\n",
    "\n",
    "        # Get the final output\n",
    "        output = torch.matmul(attn_scores, V)\n",
    "        return output\n",
    "    \n",
    "    def split(self, x):\n",
    "        # Reshape the input emb_dim (to multi-head, each head owns a part of input features) for multi-head attention\n",
    "        batch_size, seq_len, emb_dim = x.size()\n",
    "        # transpose to fix batch_size and num_heads, let seq_len, head_emb_dim participate in matrix multiplication\n",
    "        return x.view(batch_size, seq_len, self.num_heads, self.head_emb_dim).transpose(1, 2)\n",
    "\n",
    "    def combine(self, x):\n",
    "        batch_size, num_heads, seq_len, head_emb_dim = x.size()\n",
    "        # contiguous() ensures the memory layout of the tensor is contiguous\n",
    "        return x.transpose(1, 2).contiguous().view(batch_size, seq_len, self.emb_dim)\n",
    "    \n",
    "    def forward(self, Q, K, V, mask=None):\n",
    "        # Split input to multi heads\n",
    "        Q = self.split(self.W_q(Q))\n",
    "        K = self.split(self.W_k(K))\n",
    "        V = self.split(self.W_v(V))\n",
    "\n",
    "        # Perform scaled dot-product attention\n",
    "        attn_output = self.scaled_dot_product_attention(Q, K, V, mask)\n",
    "\n",
    "        # Combine outputs and apply transformation\n",
    "        output = self.W_o(self.combine(attn_output))\n",
    "        return output\n",
    "    \n",
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, emb_dim, num_heads, ffn_dim, dropout):\n",
    "        super().__init__()\n",
    "        self.self_atten = MultiHeadAttention(emb_dim, num_heads)\n",
    "        self.ffn = PositionWiseFFN(emb_dim, ffn_dim)\n",
    "        self.norm1 = nn.LayerNorm(emb_dim)\n",
    "        self.norm2 = nn.LayerNorm(emb_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        attn_output = self.self_atten(x, x, x, mask)\n",
    "        x = self.norm1(x + self.dropout(attn_output))\n",
    "        ffn_output = self.ffn(x)\n",
    "        x = self.norm2(x + self.dropout(ffn_output))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolygonEncoder(nn.Module):\n",
    "    def __init__(self, emb_dim, num_heads,\n",
    "                num_layers, ffn_dim, max_seq_len, dropout):\n",
    "        super().__init__()\n",
    "        self.encoder_layers = nn.ModuleList([EncoderLayer(emb_dim, num_heads, ffn_dim, dropout) for _ in range(num_layers)])\n",
    "        self.class_embedding = nn.Parameter(torch.randn(1, 1, emb_dim))\n",
    "        self.pos_embedding = nn.Parameter(torch.randn(1, 1 + max_seq_len, emb_dim))\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        # token_mask = (tokens != 0).unsqueeze(1).unsqueeze(2)\n",
    "        batch_size, seq_len, emb_dim = x.shape\n",
    "        class_embedding = self.class_embedding.repeat(batch_size, 1, 1)\n",
    "        x = torch.cat([class_embedding, x], dim=1)\n",
    "        # print(x.shape, self.pos_embedding[:, :seq_len+1].shape)\n",
    "        x = x + self.pos_embedding[:, :seq_len+1]\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # Create a new tensor with True values in the first column (for cls token)\n",
    "        if mask is not None:\n",
    "            cls_mask = torch.ones((batch_size, 1, 1, 1), dtype=torch.bool)\n",
    "            mask = torch.cat((cls_mask, mask), dim=3)\n",
    "        \n",
    "        for enc_layer in self.encoder_layers:\n",
    "            x = enc_layer(x, mask)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "class PolygonTransformer(nn.Module):\n",
    "    def __init__(self, num_types, emb_dim, num_heads, num_layers, ffn_dim, max_seq_len, dropout):\n",
    "        super().__init__()\n",
    "        self.encoder = PolygonEncoder(emb_dim, num_heads, num_layers, ffn_dim, max_seq_len, dropout)\n",
    "        self.mlp_head = nn.Sequential(nn.Linear(emb_dim, ffn_dim),\n",
    "                                      nn.ReLU(),\n",
    "                                      nn.Linear(ffn_dim, num_types))\n",
    "        \n",
    "    def forward(self, x, mask=None):\n",
    "        x = self.encoder(x, mask)\n",
    "        x = x[:, 0, :] # grab the class embedding\n",
    "        x = self.mlp_head(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class CompareModel(nn.Module):\n",
    "    def __init__(self, emb_dim, dense_size, dropout, output_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Define the layers\n",
    "        self.conv1 = nn.Conv1d(emb_dim, 32, kernel_size=5, padding=2)  # Assuming input channels=1\n",
    "        self.conv2 = nn.Conv1d(32, 64, kernel_size=5, padding=2)\n",
    "        self.maxpool = nn.MaxPool1d(kernel_size=3)\n",
    "        self.global_avgpool = nn.AdaptiveAvgPool1d(1)  # Global average pooling\n",
    "        self.dense1 = nn.Linear(64, dense_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.dense2 = nn.Linear(dense_size, output_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Input shape: (batch_size, seq_len, geom_vector_len)\n",
    "        # Convolutional layers\n",
    "        x = x.permute(0, 2, 1)  # Permute to (batch_size, channels, seq_len)\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.global_avgpool(x)\n",
    "        \n",
    "        # Flatten\n",
    "        x = x.view(x.size(0), -1)  # Reshape to (batch_size, num_features)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        x = self.dense1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.dense2(x)\n",
    "\n",
    "        # No need to add softmax (already included in CrossEntropyLossFunction), otherwise it will be double softmax and converge slower\n",
    "\n",
    "        return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid wkt string, skip it\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from deep_geometry import vectorizer as gv\n",
    "from deep_geometry import GeomScaler\n",
    "\n",
    "\n",
    "max_seq_len = 64\n",
    "batch_size = 32\n",
    "\n",
    "\n",
    "gs = GeomScaler()\n",
    "types_dict = {'PK':0, 'MR': 1, 'KL':2, 'NV':3, 'WA':4, 'LG':5, 'HO':6, 'GR':7, 'REC':8, 'PGK':9}\n",
    "df = pd.read_csv(\"archaeology.csv\")\n",
    "df['type'] = df['Aardspoor'].map(types_dict)\n",
    "df = df.dropna().reset_index(drop=True)\n",
    "\n",
    "def count_points(wkt):\n",
    "    try:\n",
    "        num_points = gv.num_points_from_wkt(wkt)\n",
    "        return num_points\n",
    "    except:\n",
    "        print(\"Invalid wkt string, skip it\")\n",
    "        return np.inf\n",
    "\n",
    "filtered_df = df[df['WKT'].apply(lambda x: count_points(x) <= max_seq_len)]\n",
    "df = filtered_df\n",
    "\n",
    "df = df[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_split(df, val_split_ratio, test_split_ratio):\n",
    "\n",
    "    data, labels = np.array(df['WKT'].tolist()), np.array(df['type'].tolist())\n",
    "\n",
    "    num_val = int(val_split_ratio * len(df))\n",
    "    num_test = int(test_split_ratio * len(df))\n",
    "\n",
    "    indices = np.arange(len(df))\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "    train_indices, val_indices, test_indices = indices[num_val+num_test:], indices[:num_val], indices[num_val:num_val+num_test]\n",
    "\n",
    "    train_data, train_labels = data[train_indices], labels[train_indices]\n",
    "    val_data, val_labels = data[val_indices], labels[val_indices]\n",
    "    test_data, test_labels = data[test_indices], labels[test_indices]\n",
    "\n",
    "    return train_data, train_labels, val_data, val_labels, test_data, test_labels\n",
    "\n",
    "ori_train_data, ori_train_labels, ori_val_data, ori_val_labels, ori_test_data, ori_test_labels = dataset_split(df, 0.1, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_polygon_dataset(wkts, types, max_seq_len): # TODO - 1. split into train, validate, test. 2. randomly sample\n",
    "    geoms, labels, start_points = [], [], []\n",
    "    for i, wkt in enumerate(wkts):\n",
    "        num_point = gv.num_points_from_wkt(wkt)\n",
    "        if  num_point > max_seq_len:\n",
    "             continue\n",
    "        geom = gv.vectorize_wkt(wkt, max_points=max_seq_len, fixed_size=True)\n",
    "        geoms.append(geom)\n",
    "        labels.append(types[i])\n",
    "        start_points.append(num_point)\n",
    "\n",
    "    start_points = torch.tensor(start_points).unsqueeze(1)\n",
    "    indices = torch.arange(max_seq_len).unsqueeze(0)\n",
    "    mask = indices < start_points\n",
    "    mask = mask.unsqueeze(1).unsqueeze(2)\n",
    "    tokens = np.stack(geoms, axis=0)\n",
    "    gs.fit(tokens)\n",
    "    tokens = gs.transform(tokens)\n",
    "    tokens = torch.tensor(tokens, dtype=torch.float32)\n",
    "    labels = torch.tensor(labels, dtype=torch.long)\n",
    "    \n",
    "    return tokens, labels, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your custom dataset\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tokens, train_labels, train_mask = prepare_polygon_dataset(ori_train_data, ori_train_labels, max_seq_len)\n",
    "val_tokens, val_labels, val_mask = prepare_polygon_dataset(ori_val_data, ori_val_labels, max_seq_len)\n",
    "test_tokens, test_labels, test_mask = prepare_polygon_dataset(ori_test_data, ori_test_labels, max_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_split_ratio, test_split_ratio = 0.1, 0.2\n",
    "# train_dataset, val_dataset, test_dataset = random_split(dataset, [0.7, 0.1, 0.2])\n",
    "\n",
    "train_loader = DataLoader(TensorDataset(train_tokens, train_labels, train_mask), batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(TensorDataset(val_tokens, val_labels, val_mask), batch_size=batch_size)\n",
    "test_loader = DataLoader(TensorDataset(test_tokens, test_labels, test_mask), batch_size=batch_size)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 100\n",
      "Epoch: 1, Train Loss: 2.3439272967251865, Val Loss: 2.0398702025413513, Val Acc: 0.25\n",
      "50 100\n",
      "Epoch: 2, Train Loss: 1.8595007387074558, Val Loss: 1.6315566301345825, Val Acc: 0.5\n",
      "50 100\n",
      "Epoch: 3, Train Loss: 1.5269819335504011, Val Loss: 1.4574153125286102, Val Acc: 0.5\n",
      "50 100\n",
      "Epoch: 4, Train Loss: 1.4111585508693347, Val Loss: 1.4407252669334412, Val Acc: 0.5\n",
      "50 100\n",
      "Epoch: 5, Train Loss: 1.3795641443946145, Val Loss: 1.4347845017910004, Val Acc: 0.5\n",
      "50 100\n",
      "Epoch: 6, Train Loss: 1.3639821464365178, Val Loss: 1.4345152378082275, Val Acc: 0.5\n",
      "50 100\n",
      "Epoch: 7, Train Loss: 1.3555522886189548, Val Loss: 1.4336116313934326, Val Acc: 0.5\n",
      "50 100\n",
      "Epoch: 8, Train Loss: 1.3517869223247876, Val Loss: 1.4310604929924011, Val Acc: 0.5\n",
      "50 100\n",
      "Epoch: 9, Train Loss: 1.343235655264421, Val Loss: 1.4216059744358063, Val Acc: 0.5\n",
      "50 100\n",
      "Epoch: 10, Train Loss: 1.348554020578211, Val Loss: 1.4264130592346191, Val Acc: 0.5\n",
      "50 100\n",
      "Epoch: 11, Train Loss: 1.3425350947813555, Val Loss: 1.4179042279720306, Val Acc: 0.5\n",
      "50 100\n",
      "Epoch: 12, Train Loss: 1.3446133732795715, Val Loss: 1.4129046201705933, Val Acc: 0.5\n",
      "50 100\n",
      "Epoch: 13, Train Loss: 1.3382529074495488, Val Loss: 1.4162716567516327, Val Acc: 0.5\n",
      "50 100\n",
      "Epoch: 14, Train Loss: 1.3341794880953701, Val Loss: 1.4099816679954529, Val Acc: 0.5\n",
      "50 100\n",
      "Epoch: 15, Train Loss: 1.3356464342637495, Val Loss: 1.4149884581565857, Val Acc: 0.5\n",
      "50 100\n",
      "Epoch: 16, Train Loss: 1.3368729461323132, Val Loss: 1.4151145815849304, Val Acc: 0.5\n",
      "50 100\n",
      "Epoch: 17, Train Loss: 1.3411722643808885, Val Loss: 1.4106555581092834, Val Acc: 0.5\n",
      "50 100\n",
      "Epoch: 18, Train Loss: 1.3340857056054203, Val Loss: 1.4101085662841797, Val Acc: 0.5\n",
      "50 100\n",
      "Epoch: 19, Train Loss: 1.3348009586334229, Val Loss: 1.4113093316555023, Val Acc: 0.5\n",
      "50 100\n",
      "Epoch: 20, Train Loss: 1.3302125876600093, Val Loss: 1.4115702509880066, Val Acc: 0.5\n",
      "110 200\n",
      "Test Loss: 1.2241201571055822, Test Acc: 0.55\n"
     ]
    }
   ],
   "source": [
    "pot = PolygonTransformer(num_types=10,\n",
    "                        emb_dim=7,\n",
    "                        num_heads=1,\n",
    "                        num_layers=1,\n",
    "                        ffn_dim=64, \n",
    "                        max_seq_len=max_seq_len,\n",
    "                        dropout=0.5)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(pot.parameters(), lr=0.001, betas=(0.9, 0.98), eps=1e-9)\n",
    "\n",
    "num_epochs = 20\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    pot.train()\n",
    "    train_loss = 0.0\n",
    "    for batch_x, batch_y, batch_mask in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = pot(batch_x, batch_mask)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    pot.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_x, batch_y, batch_mask in val_loader:\n",
    "            outputs = pot(batch_x, batch_mask)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += batch_y.size(0)\n",
    "            correct += (predicted == batch_y).sum().item()\n",
    "    val_loss /= len(val_loader)\n",
    "    val_acc = correct / total\n",
    "    print(correct, total)\n",
    "    print(f\"Epoch: {epoch+1}, Train Loss: {train_loss/len(train_loader)}, Val Loss: {val_loss}, Val Acc: {val_acc}\")\n",
    "\n",
    "\n",
    "# Test\n",
    "pot.eval()\n",
    "test_loss = 0.0\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for batch_x, batch_y, batch_mask in test_loader:\n",
    "        outputs = pot(batch_x, batch_mask)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        test_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += batch_y.size(0)\n",
    "        correct += (predicted == batch_y).sum().item()\n",
    "test_loss /= len(test_loader)\n",
    "test_acc = correct / total\n",
    "print(correct, total)\n",
    "print(f\"Test Loss: {test_loss}, Test Acc: {test_acc}\")\n",
    "\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Conv\n",
    "##### refer to https://arxiv.org/pdf/1806.03857.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(wkts, types):\n",
    "    train_geoms = [gv.vectorize_wkt(wkt) for wkt in wkts]\n",
    "    \n",
    "    zipped = zip(train_geoms, types)\n",
    "    train_input_sorted = {}\n",
    "    train_labels_sorted = {}\n",
    "\n",
    "    for geom, label in sorted(zipped, key=lambda x: len(x[0]), reverse=True):\n",
    "        seq_len = geom.shape[0]\n",
    "        if seq_len in train_input_sorted:\n",
    "            train_input_sorted[seq_len].append(geom)\n",
    "            train_labels_sorted[seq_len].append(label)\n",
    "        else:\n",
    "            train_input_sorted[seq_len] = [geom]\n",
    "            train_labels_sorted[seq_len] = [label]\n",
    "    \n",
    "    return train_input_sorted, train_labels_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_sorted, train_labels_sorted = prepare_dataset(ori_train_data, ori_train_labels)\n",
    "val_input_sorted, val_labels_sorted = prepare_dataset(ori_val_data, ori_val_labels)\n",
    "test_input_sorted, test_labels_sorted = prepare_dataset(ori_test_data, ori_test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_454398/635786605.py:22: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  inputs = torch.tensor(train_input_sorted[seq_len], dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Train Loss: 1.750279100329083, Val Loss: 1.7481615116650409, Val Acc: 0.42\n",
      "Epoch: 2, Train Loss: 1.6493894674682192, Val Loss: 1.7513299360871315, Val Acc: 0.42\n",
      "Epoch: 3, Train Loss: 1.5751746207741755, Val Loss: 1.6024222306229852, Val Acc: 0.42\n",
      "Epoch: 4, Train Loss: 1.574350695524897, Val Loss: 1.5898822071877392, Val Acc: 0.42\n",
      "Epoch: 5, Train Loss: 1.4812576020402568, Val Loss: 1.6561916362155567, Val Acc: 0.42\n",
      "Epoch: 6, Train Loss: 1.5116444474884443, Val Loss: 1.5549000718376853, Val Acc: 0.42\n",
      "Epoch: 7, Train Loss: 1.4578267909320337, Val Loss: 1.536852504042062, Val Acc: 0.42\n",
      "Epoch: 8, Train Loss: 1.4505472257733345, Val Loss: 1.429783984002742, Val Acc: 0.48\n",
      "Epoch: 9, Train Loss: 1.4093484234597002, Val Loss: 1.4115639606660062, Val Acc: 0.48\n",
      "Epoch: 10, Train Loss: 1.3526019068168742, Val Loss: 1.402777267450636, Val Acc: 0.48\n",
      "Epoch: 11, Train Loss: 1.3342372248215335, Val Loss: 1.4839567657221446, Val Acc: 0.46\n",
      "Epoch: 12, Train Loss: 1.410335760563612, Val Loss: 1.397323833947832, Val Acc: 0.48\n",
      "Epoch: 13, Train Loss: 1.3823994753350104, Val Loss: 1.4278842722150413, Val Acc: 0.48\n",
      "Epoch: 14, Train Loss: 1.409378848437752, Val Loss: 1.3540836335583166, Val Acc: 0.52\n",
      "Epoch: 15, Train Loss: 1.3265262211539917, Val Loss: 1.4240264709700237, Val Acc: 0.5\n",
      "Epoch: 16, Train Loss: 1.3873743095568247, Val Loss: 1.3659658418460325, Val Acc: 0.52\n",
      "Epoch: 17, Train Loss: 1.2732641361653805, Val Loss: 1.319703652777455, Val Acc: 0.53\n",
      "Epoch: 18, Train Loss: 1.3395297543278761, Val Loss: 1.3215064795857125, Val Acc: 0.52\n",
      "Epoch: 19, Train Loss: 1.3024228088823813, Val Loss: 1.3724456671625376, Val Acc: 0.5\n",
      "Epoch: 20, Train Loss: 1.2951453708644425, Val Loss: 1.3643474673682994, Val Acc: 0.5\n",
      "Test Loss: 1.367470873253686, Test Acc: 0.35333333333333333\n"
     ]
    }
   ],
   "source": [
    "# Create training data\n",
    "sequence_length = 10\n",
    "geom_vector_len = 7  # Assuming geom_vector_len is known\n",
    "dense_size = 64  # Size of the dense layer\n",
    "dropout = 0.5  # Dropout rate\n",
    "num_classes = 10  # Number of output classes\n",
    "batch_size = 32\n",
    "\n",
    "# Define the model, loss function, and optimizer\n",
    "conv_model = CompareModel(emb_dim=geom_vector_len, dense_size=dense_size, dropout=dropout, output_size=num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(conv_model.parameters(), lr=0.001, betas=(0.9, 0.98), eps=1e-9)\n",
    "\n",
    "# Training process\n",
    "num_epochs = 20\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    conv_model.train()\n",
    "    train_loss = 0.0\n",
    "    total_batch_train = 0\n",
    "    for seq_len in train_input_sorted:\n",
    "        inputs = torch.tensor(train_input_sorted[seq_len], dtype=torch.float32)\n",
    "        labels = torch.tensor(train_labels_sorted[seq_len], dtype=torch.long)\n",
    "        dataset = TensorDataset(inputs, labels)\n",
    "        loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "        for batch_x, batch_y in loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = conv_model(batch_x)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "            total_batch_train += 1\n",
    "\n",
    "    conv_model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    total_batch_val = 0\n",
    "    with torch.no_grad():\n",
    "        for seq_len in val_input_sorted:\n",
    "            inputs = torch.tensor(val_input_sorted[seq_len], dtype=torch.float32)\n",
    "            labels = torch.tensor(val_labels_sorted[seq_len], dtype=torch.long)\n",
    "            dataset = TensorDataset(inputs, labels)\n",
    "            loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "            for batch_x, batch_y in loader:\n",
    "                outputs = conv_model(batch_x)\n",
    "                loss = criterion(outputs, batch_y)\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total += batch_y.size(0)\n",
    "                total_batch_val += 1\n",
    "                correct += (predicted == batch_y).sum().item()\n",
    "    val_loss /= total_batch_val\n",
    "    val_acc = correct / total\n",
    "    print(f\"Epoch: {epoch+1}, Train Loss: {train_loss/total_batch_train}, Val Loss: {val_loss}, Val Acc: {val_acc}\")\n",
    "\n",
    "# Test\n",
    "conv_model.eval()\n",
    "test_loss = 0.0\n",
    "correct = 0\n",
    "total_batch_test = 0\n",
    "with torch.no_grad():\n",
    "    for seq_len in test_input_sorted:\n",
    "        inputs = torch.tensor(test_input_sorted[seq_len], dtype=torch.float32)\n",
    "        labels = torch.tensor(test_labels_sorted[seq_len], dtype=torch.long)\n",
    "        dataset = TensorDataset(inputs, labels)\n",
    "        loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "        for batch_x, batch_y in loader:\n",
    "            outputs = conv_model(batch_x)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += batch_y.size(0)\n",
    "            total_batch_test += 1\n",
    "            correct += (predicted == batch_y).sum().item()\n",
    "test_loss /= total_batch_test\n",
    "test_acc = correct / total\n",
    "print(f\"Test Loss: {test_loss}, Test Acc: {test_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters in the Conv model: 16266\n",
      "Total number of parameters in the Transformer model: 5979\n"
     ]
    }
   ],
   "source": [
    "# Count the number of parameters\n",
    "total_params_conv_model = sum(p.numel() for p in conv_model.parameters())\n",
    "print(f\"Total number of parameters in the Conv model: {total_params_conv_model}\")\n",
    "\n",
    "total_params_pot_model = sum(p.numel() for p in pot.parameters())\n",
    "print(f\"Total number of parameters in the Transformer model: {total_params_pot_model}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_a4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

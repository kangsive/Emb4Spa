{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.interpolate import interp1d\n",
    "import matplotlib.pyplot as plt\n",
    "from shapely.geometry import Polygon, LineString, Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 63, 2)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Create a sample tensor\n",
    "tensor = np.random.rand(32, 64, 2)\n",
    "\n",
    "# Compute the differences along the second dimension\n",
    "diff_tensor = np.diff(tensor, axis=1)\n",
    "\n",
    "print(diff_tensor.shape)  # Output: (32, 63, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dingkang/envs/nlp_a4/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 63, 2])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Create a sample tensor\n",
    "tensor = torch.rand(32, 64, 2)\n",
    "\n",
    "# Compute the differences along the second dimension\n",
    "diff_tensor = tensor[:, 1:, :] - tensor[:, :-1, :]\n",
    "\n",
    "print(diff_tensor.shape)  # Output: torch.Size([32, 63, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "# Define the encoder\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        _, (h, c) = self.lstm(input_seq)\n",
    "        return h, c\n",
    "\n",
    "# Define the decoder\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, input_seq, h, c):\n",
    "        batch_size, seq_len, _ = input_seq.shape\n",
    "        z = h.reshape(batch_size, 1, -1).repeat(1, seq_len, 1)\n",
    "        input_seq = torch.cat([z, input_seq], dim=-1)\n",
    "        output, _ = self.lstm(input_seq, (h, c))\n",
    "        output = self.fc(output)\n",
    "        return output\n",
    "\n",
    "# Define the sequence-based encoder-decoder model\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        h, c = self.encoder(input_seq)\n",
    "        output = self.decoder(input_seq, h, c)\n",
    "        return output\n",
    "\n",
    "# Training example\n",
    "input_size = 2\n",
    "hidden_size = 128\n",
    "output_size = 2\n",
    "seq_length = 10\n",
    "batch_size = 32\n",
    "num_epochs = 100\n",
    "\n",
    "# Generate random training data\n",
    "train_data = torch.randn(batch_size, seq_length, input_size)\n",
    "\n",
    "# Initialize model, loss function, and optimizer\n",
    "encoder = Encoder(input_size, hidden_size)\n",
    "decoder = Decoder(input_size + hidden_size, hidden_size, output_size)\n",
    "model = Seq2Seq(encoder, decoder)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Forward pass\n",
    "    output = model(train_data)\n",
    "    \n",
    "    # Compute loss\n",
    "    loss = criterion(output, train_data)\n",
    "    \n",
    "    # Backward pass and optimization\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Print progress\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def compute_NN(X, Y):\n",
    "    X, Y = np.array(X), np.array(Y)\n",
    "    neigh = NearestNeighbors(n_neighbors = 1)\n",
    "    neigh.fit(X)\n",
    "\n",
    "    knn_array = neigh.kneighbors(return_distance=False)\n",
    "    knn_array = knn_array.reshape(1, -1)    # for k=1, we can flaten the array\n",
    "    matches = Y[knn_array] == Y     # Match nns' labels with corresponding y\n",
    "    avg_acc = matches.mean()\n",
    "\n",
    "    return avg_acc\n",
    "\n",
    "def compute_FT(X, Y, k=None):\n",
    "    X, Y = np.array(X), np.array(Y)\n",
    "    types, k_list = np.unique(Y, return_counts=True)\n",
    "    neigh = NearestNeighbors(n_neighbors = k)\n",
    "    neigh.fit(X)\n",
    "\n",
    "    avg_acc = 0\n",
    "\n",
    "    for i in range(len(types)):\n",
    "        X_t, k = X[Y == types[i]], k_list[i]\n",
    "        knn_array = neigh.kneighbors(X_t, n_neighbors=k, return_distance=False)     # Get knn for every instance\n",
    "        Y_t = np.full(knn_array.shape, types[i])    # create ground truth for every nn\n",
    "        matches = Y[knn_array] == Y_t    # Match knns' labels with corresponding y\n",
    "        avg_acc += (matches.sum(axis=-1)/k).mean()   # Calulate acc of each row (instance) and average them\n",
    "\n",
    "    return avg_acc/len(k_list)\n",
    "\n",
    "\n",
    "def compute_ST(X, Y, k=None):\n",
    "    X, Y = np.array(X), np.array(Y)\n",
    "    types, k_list = np.unique(Y, return_counts=True)\n",
    "    neigh = NearestNeighbors(n_neighbors = k)\n",
    "    neigh.fit(X)\n",
    "\n",
    "    avg_acc = 0\n",
    "\n",
    "    for i in range(len(types)):\n",
    "        X_t, k = X[Y == types[i]], k_list[i]\n",
    "        knn_array = neigh.kneighbors(X_t, n_neighbors=2*k, return_distance=False)     # Now we look at top 2*k nns\n",
    "        Y_t = np.full(knn_array.shape, types[i])    # create ground truth for every nn\n",
    "        matches = Y[knn_array] == Y_t    # Match knns' labels with corresponding y\n",
    "        avg_acc += (matches.sum(axis=-1)/k).mean()   # Calulate acc of each row (instance) and average them\n",
    "\n",
    "    return avg_acc/len(k_list)\n",
    "\n",
    "    # return round(correct*1.0/k, 3), knn_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "loaded = np.load(\"dataset/train_building_shape_5k.npz\")\n",
    "\n",
    "split_ratio = 0.2\n",
    "train_tokens, val_tokens, train_labels, val_labels = train_test_split(loaded[\"train_tokens\"], loaded[\"train_labels\"], test_size=split_ratio, random_state=42)\n",
    "# train_tokens, train_labels = loaded[\"train_tokens\"], loaded[\"train_labels\"]\n",
    "\n",
    "train_tokens = train_tokens.reshape(train_tokens.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.428367780917627, 0.5544760435345489)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute_NN(train_tokens, train_labels)\n",
    "compute_FT(train_tokens, train_labels), compute_ST(train_tokens, train_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.prepare_dataset import prepare_dataset_mnist\n",
    "max_seq_len = 64\n",
    "batch_size = 64\n",
    "dataset_size = None\n",
    "with_mask = False\n",
    "\n",
    "train_tokens, train_labels, train_mask, val_tokens, val_labels, val_mask = prepare_dataset_mnist(file=\"dataset/building_shapes_5010.csv\",\n",
    "                                                                                                 with_mask=with_mask,\n",
    "                                                                                                 split_ratio=0.2,\n",
    "                                                                                                 dataset_size=dataset_size,\n",
    "                                                                                                 max_seq_len=max_seq_len,\n",
    "                                                                                                 train=True)\n",
    "\n",
    "train_tokens = train_tokens[:, :, :2]\n",
    "train_tokens = train_tokens.reshape(train_tokens.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.15763092303377366, 0.257442129680529)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_FT(train_tokens, train_labels), compute_ST(train_tokens, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def min_max_normalize(data):\n",
    "    # Compute min and max values along the num_features dimension\n",
    "    min_vals = np.min(data, axis=(1, 2), keepdims=True)\n",
    "    max_vals = np.max(data, axis=(1, 2), keepdims=True)\n",
    "    \n",
    "    # Perform min-max normalization\n",
    "    a = data - min_vals\n",
    "    normalized_data = (data - min_vals) / (max_vals - min_vals)\n",
    "    \n",
    "    return normalized_data\n",
    "\n",
    "# Example dataset\n",
    "batch_size = 2\n",
    "sequence_length = 3\n",
    "num_features = 2\n",
    "dataset = np.random.rand(batch_size, sequence_length, num_features)\n",
    "\n",
    "# Normalize the dataset\n",
    "normalized_dataset = min_max_normalize(dataset)\n",
    "\n",
    "print(\"Original Dataset:\")\n",
    "print(dataset)\n",
    "print(\"\\nNormalized Dataset:\")\n",
    "print(normalized_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from shapely import wkt\n",
    "from shapely.geometry import Polygon\n",
    "import rasterio.features\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "def raterize_poly(file=None, size=28):\n",
    "    df = pd.read_csv(file)\n",
    "    df = df[:5000]\n",
    "    wkts = df['wkt'].to_numpy()\n",
    "    labels = df['label'].to_numpy()\n",
    "\n",
    "    geom_xy = [wkt.loads(wkt_str).boundary.coords.xy for wkt_str in wkts]\n",
    "\n",
    "    imgs = np.zeros((len(geom_xy), size, size))\n",
    "\n",
    "    for i, xy in enumerate(geom_xy):\n",
    "        vec = np.array(xy).T\n",
    "        min = vec.min(axis=0, keepdims=True)\n",
    "        max = vec.max(axis=0, keepdims=True)\n",
    "\n",
    "        # Map to the range [0, 1]\n",
    "        vec = (vec - min) / (max - min)\n",
    "        \n",
    "        # zoom out 10% to ensure the integrity of the shape\n",
    "        vec = vec * 0.9\n",
    "\n",
    "        # Get centroid and shift to the center (0.5, 0.5)\n",
    "        min = vec.min(axis=0, keepdims=True)\n",
    "        max = vec.max(axis=0, keepdims=True)\n",
    "\n",
    "        centroid = (max + min) / 2\n",
    "        shift = (np.array([0.5, 0.5]) - centroid)[0] # remove redundant dimension\n",
    "\n",
    "        vec[:, 0] += shift[0]\n",
    "        vec[:, 1] += shift[0]\n",
    "\n",
    "        vec = vec * size\n",
    "\n",
    "        poly = Polygon(vec)\n",
    "        img = rasterio.features.rasterize([poly], out_shape=(size, size), fill=1, default_value=0)\n",
    "\n",
    "        imgs[i] = img\n",
    "\n",
    "    return imgs, labels, wkts\n",
    "    \n",
    "\n",
    "# # poly = Polygon([(0, 50), (10, 10), (30, 0), (45, 45), (0, 50)])\n",
    "# poly = reverse_vector_polygon(train_tokens[100]*28)\n",
    "# img = rasterio.features.rasterize([poly], out_shape=(28, 28), fill=1, default_value=0)\n",
    "# plt.imshow(img, cmap='gray', vmin=0, vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs, labels, wkts = raterize_poly(\"dataset/building_shapes_5010.csv\", 28)\n",
    "\n",
    "# np.savez(\"dataset/raterized_building_shapes.npz\", train_tokens=imgs, train_labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x79fe5b2584c0>"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(imgs[100], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"100.0\" height=\"100.0\" viewBox=\"84460.02236045079 46095.501757453865 30.995891188867972 23.929993135345285\" preserveAspectRatio=\"xMinYMin meet\"><g transform=\"matrix(1,0,0,-1,0,92214.93350804308)\"><path fill-rule=\"evenodd\" fill=\"#66cc99\" stroke=\"#555555\" stroke-width=\"0.6199178237773595\" opacity=\"0.6\" d=\"M 84470.02547240656,46097.65050411452 L 84470.76939061252,46111.70229240921 L 84461.29303350837,46111.50486831222 L 84461.26827462744,46112.241161855345 L 84461.1885325052,46114.612578168926 L 84461.17035642076,46118.28375461925 L 84480.03634271749,46117.74681872916 L 84479.50934950716,46107.553794110616 L 84479.39129674551,46105.270435102706 L 84489.82806060728,46105.222339421925 L 84489.8702556697,46096.64975342382 L 84479.07732389473,46096.72684579384 L 84470.02547240656,46097.65050411452 z\" /></g></svg>"
      ],
      "text/plain": [
       "<POLYGON ((84470.025 46097.651, 84470.769 46111.702, 84461.293 46111.505, 84...>"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wkt.loads(wkts[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_to_center(vec):\n",
    "    mins = vec.min(axis=0, keepdims=True)\n",
    "    maxs = vec.min(axis=0, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        act_fn = nn.GELU\n",
    "        self.net1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 3, kernel_size=3, stride=1, padding=1),\n",
    "            act_fn(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, return_indices=True))\n",
    "        \n",
    "        self.net2 = nn.Sequential(nn.Conv2d(3, 18, kernel_size=3, stride=1, padding=1),\n",
    "            act_fn(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, return_indices=True))\n",
    "\n",
    "        self.net3 = nn.Sequential(\n",
    "            nn.Conv2d(18, 8, kernel_size=3, stride=1, padding=1),\n",
    "            act_fn(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=1, return_indices=True),\n",
    "        )\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, indices1 = self.net1(x)\n",
    "        x, indices2 = self.net2(x)\n",
    "        x, indices3 = self.net3(x)\n",
    "        x = self.flatten(x)\n",
    "        return x, [indices1, indices2, indices3]\n",
    "    \n",
    "\n",
    "class Decoder(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.act_fn = nn.GELU()\n",
    "        self.mup1 = nn.MaxUnpool2d(kernel_size=2, stride=2)\n",
    "        self.conv1 = nn.ConvTranspose2d(8, 18, kernel_size=3, stride=1, padding=1)\n",
    "        self.mup2 = nn.MaxUnpool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.ConvTranspose2d(18, 3, kernel_size=3, stride=1, padding=1)\n",
    "        self.mup3 = nn.MaxUnpool2d(kernel_size=2, stride=2)\n",
    "        self.conv3 = nn.ConvTranspose2d(3, 1, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "    def forward(self, x, indices_list):\n",
    "        x = x.reshape(x.shape[0], -1, 4, 4)\n",
    "        # x = self.net(x, indices_list[0])\n",
    "        print(x.shape)\n",
    "        x = self.mup1(x, indices_list[2], output_size=(x.shape[0], x.shape[0], 7, 7))\n",
    "        x = self.act_fn(self.conv1(x))\n",
    "        x = self.mup2(x, indices_list[1])\n",
    "        x = self.act_fn(self.conv2(x))\n",
    "        x = self.mup3(x, indices_list[0])\n",
    "        x = self.act_fn(self.conv3(x))\n",
    "        return x\n",
    "    \n",
    "class PixelNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder()\n",
    "        self.decoder = Decoder()\n",
    "        self.loss_func = nn.MSELoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        hidden = self.encoder\n",
    "        output = self.decoder(hidden)\n",
    "        loss = self.loss_func(x, output, reduction=\"none\")\n",
    "        loss = loss.sum(dim=[1,2,3]).mean(dim=[0])\n",
    "        return hidden, output, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.randn(2, 1, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 8, 4, 4])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 28, 28])"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = Encoder(nn.GELU)\n",
    "decoder = Decoder()\n",
    "# data = data.permute(2, 0, 1)\n",
    "data.shape\n",
    "encoded, indices_list = encoder(data)\n",
    "decoder(encoded, indices_list).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely import wkt\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"dataset/mnist_polygon_test_2k.csv\")\n",
    "wkts = df['wkt'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"100.0\" height=\"100.0\" viewBox=\"0.19326752779525902 -0.010238230190263573 0.6414129481317569 0.7679049936321215\" preserveAspectRatio=\"xMinYMin meet\"><g transform=\"matrix(1,0,0,-1,0,0.7474285332515943)\"><path fill-rule=\"evenodd\" fill=\"#66cc99\" stroke=\"#555555\" stroke-width=\"0.01535809987264243\" opacity=\"0.6\" d=\"M 0.3157544175554352,0.046875 L 0.3125,0.0521564653761032 L 0.3072359675312128,0.0625 L 0.3042842297636275,0.078125 L 0.3046902423318427,0.09375 L 0.3084496083024815,0.109375 L 0.3125,0.1168929054366821 L 0.3178597976972065,0.125 L 0.328125,0.1391344456392346 L 0.3291023730290455,0.140625 L 0.3353230356518912,0.15625 L 0.3388406757559878,0.171875 L 0.34375,0.1822795923825104 L 0.3467470526334694,0.1875 L 0.359375,0.1986443238331841 L 0.3640941690940162,0.203125 L 0.375,0.2152085869919781 L 0.3776820981416179,0.21875 L 0.3855498176215764,0.234375 L 0.390625,0.2466586610487133 L 0.3925808137928574,0.25 L 0.3989647656192407,0.265625 L 0.4052014221499339,0.28125 L 0.40625,0.2832452646290299 L 0.4126390653552028,0.296875 L 0.421875,0.309077104131802 L 0.4252708258569565,0.3125 L 0.4375,0.3245493358427731 L 0.4407692775596376,0.328125 L 0.453125,0.3434442798530796 L 0.4533432979319159,0.34375 L 0.46875,0.3592187884269483 L 0.4689194508618089,0.359375 L 0.484375,0.3740259590283396 L 0.4853947823220092,0.375 L 0.4931654621400316,0.390625 L 0.491582798420661,0.40625 L 0.484375,0.4153256433881157 L 0.470262505803992,0.421875 L 0.46875,0.4224032251567392 L 0.453125,0.4251786788948676 L 0.4375,0.4259221576455648 L 0.421875,0.4245700182375583 L 0.407770667607296,0.421875 L 0.40625,0.4215881636059976 L 0.390625,0.4185398464092437 L 0.375,0.4164361978430162 L 0.359375,0.4157193916086982 L 0.34375,0.4173435547962616 L 0.330680186088481,0.421875 L 0.328125,0.4228695532190507 L 0.3125,0.4327474875098833 L 0.3058462155578491,0.4375 L 0.296875,0.4426989053089283 L 0.28125,0.4468911755668548 L 0.265625,0.4490355753329587 L 0.2527855572097317,0.453125 L 0.25,0.4545059428004831 L 0.2378114531679678,0.46875 L 0.234375,0.4759955212491596 L 0.2305759569262206,0.484375 L 0.2248367396425569,0.5 L 0.2217084534853376,0.515625 L 0.2232786692428997,0.53125 L 0.2295479696749669,0.546875 L 0.234375,0.5539034004820897 L 0.2412736107417497,0.5625 L 0.25,0.571131533687437 L 0.257352592661639,0.578125 L 0.265625,0.586486632547214 L 0.2716814026410222,0.59375 L 0.28125,0.6064112013606962 L 0.2836906592321212,0.609375 L 0.296875,0.6204851137465217 L 0.3074655182086534,0.625 L 0.3125,0.6269945670237823 L 0.328125,0.6304368548644022 L 0.34375,0.6370425588078685 L 0.3479748696438433,0.640625 L 0.359375,0.648494240723559 L 0.3737686055033641,0.65625 L 0.3749999999999999,0.6568212787126679 L 0.390625,0.6631081967413273 L 0.40625,0.6697216886413893 L 0.4101022065596847,0.671875 L 0.421875,0.6787130925641662 L 0.4362236935274454,0.6875 L 0.4375000000000001,0.6882590921378962 L 0.453125,0.695434627060644 L 0.46875,0.6985688516748614 L 0.484375,0.6990288929752506 L 0.5,0.7001896565739234 L 0.5100787487038398,0.703125 L 0.515625,0.7053506733848735 L 0.53125,0.714336336615182 L 0.5402140688063264,0.71875 L 0.546875,0.7215111369105247 L 0.5625,0.7252122062597478 L 0.578125,0.7277826748336111 L 0.59375,0.7292258377517793 L 0.609375,0.7277641502256231 L 0.625,0.7204725296946886 L 0.6272548265714801,0.71875 L 0.640625,0.7079748951011295 L 0.6545974321191491,0.703125 L 0.65625,0.7027291666291645 L 0.671875,0.7009755623837093 L 0.6875,0.6985479058960007 L 0.703125,0.6951043815859814 L 0.71875,0.6923774670094485 L 0.734375,0.6899282177251664 L 0.7412537479383207,0.6875 L 0.75,0.683477036214571 L 0.7615342125899336,0.671875 L 0.765625,0.665961393516103 L 0.7712476557518153,0.65625 L 0.78125,0.6418166079524958 L 0.7822442280509951,0.640625 L 0.795872589685593,0.625 L 0.796875,0.6234595454851525 L 0.8039114035716566,0.609375 L 0.8062395502369373,0.59375 L 0.8058878401317715,0.578125 L 0.8037577495786896,0.5625 L 0.7990640027814657,0.546875 L 0.796875,0.5428774993225743 L 0.7892813444656452,0.53125 L 0.78125,0.5204153718421265 L 0.7784139806791952,0.515625 L 0.7693896384675399,0.5 L 0.765625,0.4952521310616801 L 0.7544120805257856,0.484375 L 0.75,0.4811202143619038 L 0.734375,0.4719502694764949 L 0.7296068434714169,0.46875 L 0.71875,0.4596746071549795 L 0.7120457255403101,0.453125 L 0.703125,0.4447520549080259 L 0.6952385032285138,0.4375 L 0.6875,0.4312103769795735 L 0.6743147849823482,0.421875 L 0.671875,0.420075065017344 L 0.65625,0.4103885117528359 L 0.6501852635195121,0.40625 L 0.640625,0.3970852023523091 L 0.6347569811967255,0.390625 L 0.625,0.3806760483166308 L 0.6185182214451261,0.375 L 0.609375,0.3676684033300587 L 0.6016225532830723,0.359375 L 0.5939050392760372,0.34375 L 0.59375,0.3433468966693483 L 0.5883890753253465,0.328125 L 0.5801541925573849,0.3125 L 0.578125,0.3098665334017864 L 0.5671185405997208,0.296875 L 0.5625,0.2913764999768925 L 0.5546864876217196,0.28125 L 0.546875,0.272665190955277 L 0.540028488285197,0.265625 L 0.53125,0.2575502332037994 L 0.5239254201691376,0.25 L 0.515625,0.2372835564102021 L 0.513829050166613,0.234375 L 0.5065126712487695,0.21875 L 0.5,0.2091523951544244 L 0.4957112035095046,0.203125 L 0.484375,0.1886193430152134 L 0.483564316690911,0.1875 L 0.4728532774738132,0.171875 L 0.4687500000000001,0.1660770272064957 L 0.4618494803857779,0.15625 L 0.453125,0.141796901558896 L 0.4524143273644728,0.140625 L 0.4438557918917566,0.125 L 0.4375,0.1163303365339538 L 0.4317433703428256,0.109375 L 0.421875,0.0958418743291807 L 0.4205287083956956,0.09375 L 0.4143234167500014,0.078125 L 0.408790525457903,0.0625 L 0.40625,0.0580543330989717 L 0.3990017609725255,0.046875 L 0.390625,0.0373529779225186 L 0.3848474788416396,0.03125 L 0.375,0.0233105135410507 L 0.359375,0.018202695499815 L 0.34375,0.020045753913318 L 0.328125,0.0309646450673931 L 0.3278474105176492,0.03125 L 0.3157544175554352,0.046875 z M 0.3862127878137173,0.5 L 0.390625,0.5017177005028285 L 0.40625,0.5076007048535066 L 0.421875,0.5095162313147872 L 0.4375,0.5093111311686633 L 0.453125,0.510129867688025 L 0.46875,0.5105484164857514 L 0.484375,0.5084593796884771 L 0.5,0.5063467123249757 L 0.515625,0.507701605035851 L 0.53125,0.5123667994114433 L 0.5410755559474786,0.515625 L 0.546875,0.5174558707288862 L 0.5625,0.5194362083244887 L 0.578125,0.5194136019676067 L 0.59375,0.520787275508311 L 0.6092715105723002,0.53125 L 0.6057203303629641,0.546875 L 0.5944628001329622,0.5625 L 0.59375,0.5640386479865891 L 0.5899623134540164,0.578125 L 0.5906198878614595,0.59375 L 0.5912569636012289,0.609375 L 0.5866609756791741,0.625 L 0.578125,0.637171047924688 L 0.5725874202016268,0.640625 L 0.5625,0.645698910781938 L 0.546875,0.6415907378881165 L 0.5452289898974632,0.640625 L 0.53125,0.6335086908502818 L 0.515625,0.630322107406749 L 0.5,0.629406810301875 L 0.486652618245569,0.625 L 0.484375,0.623905350020978 L 0.4702053783460313,0.609375 L 0.46875,0.6074578287379993 L 0.453125,0.5956691399675694 L 0.4375,0.5943767234307948 L 0.4252054462515736,0.59375 L 0.421875,0.5935981334126542 L 0.40625,0.5848086265846626 L 0.3997488854327715,0.578125 L 0.390625,0.569422356579422 L 0.3817598200039257,0.5625 L 0.3750000000000001,0.5584824066900691 L 0.359375,0.5513737773953704 L 0.3525436186648813,0.546875 L 0.34375,0.5355927667758724 L 0.3414440193218091,0.53125 L 0.3402696046829502,0.515625 L 0.34375,0.5076231755186726 L 0.3502914655341117,0.5 L 0.359375,0.495427292272187 L 0.375,0.4959132919899954 L 0.3862127878137173,0.5 z M 0.640625,0.5549215457503319 L 0.65625,0.5497622399520278 L 0.671875,0.5514751305270374 L 0.6848321988522705,0.5625 L 0.6844826800592267,0.578125 L 0.677253481115287,0.59375 L 0.671875,0.6031239917558416 L 0.6675161866971527,0.609375 L 0.6575421801990426,0.625 L 0.65625,0.6264899892362662 L 0.640625,0.6293543361631952 L 0.6349224168247924,0.625 L 0.6266403208924046,0.609375 L 0.6274515375037146,0.59375 L 0.6299003591877603,0.578125 L 0.6336740803126912,0.5625 L 0.640625,0.554921545750332 L 0.640625,0.5549215457503319 z\" /></g></svg>"
      ],
      "text/plain": [
       "<POLYGON ((0.316 0.047, 0.312 0.052, 0.307 0.062, 0.304 0.078, 0.305 0.094, ...>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape = wkt.loads(wkts[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate_polygon(polygon, num_points=64):\n",
    "    \"\"\"\n",
    "    Interpolate simply polygon to have given number of points\n",
    "    @param: shapely polygon\n",
    "    @return: the interpolated polygon\n",
    "   \"\"\"\n",
    "    num_points = 64\n",
    "    sub_shapes = [polygon.exterior] + [interior for interior in polygon.interiors] if len(polygon.interiors) else [polygon.exterior]\n",
    "    num_list =  [len(sub_shape.coords) for sub_shape in sub_shapes]\n",
    "    total_length = sum(num_list)\n",
    "    interp_num = [int(length/total_length*num_points) for length in num_list] # assin num_points according to length\n",
    "    interp_num[0] += num_points - sum(interp_num) # insure the total num of points is equal to given\n",
    "\n",
    "    interp_points = [[sub_shape.interpolate(distance) for distance in np.linspace(0, sub_shape.length, interp_num[i])]\n",
    "                        for i, sub_shape in enumerate(sub_shapes)] # get interpolated points for each sub_shape\n",
    "\n",
    "    shell = [[point.x, point.y] for point in interp_points[0]]\n",
    "    holes = [[[point.x, point.y] for point in sub_points] for sub_points in interp_points[1:]] if len(interp_points) > 1 else None\n",
    "    return Polygon(shell=shell, holes=holes) # create new polygon from interpolated points\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "polygon = interpolate_polygon(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"100.0\" height=\"100.0\" viewBox=\"0.1965280037900647 -0.008262981939174206 0.6380202822993648 0.7643358680172895\" preserveAspectRatio=\"xMinYMin meet\"><g transform=\"matrix(1,0,0,-1,0,0.7478099041389411)\"><path fill-rule=\"evenodd\" fill=\"#66cc99\" stroke=\"#555555\" stroke-width=\"0.01528671736034579\" opacity=\"0.6\" d=\"M 0.3157544175554352,0.046875 L 0.3046902423318427,0.09375 L 0.34375,0.1822795923825104 L 0.3776820981416179,0.21875 L 0.4126390653552028,0.296875 L 0.4853947823220092,0.375 L 0.491582798420661,0.40625 L 0.453125,0.4251786788948676 L 0.34375,0.4173435547962616 L 0.25,0.4545059428004831 L 0.2248367396425569,0.5 L 0.2295479696749669,0.546875 L 0.296875,0.6204851137465217 L 0.453125,0.695434627060644 L 0.546875,0.7215111369105247 L 0.609375,0.7277641502256231 L 0.75,0.683477036214571 L 0.8062395502369373,0.59375 L 0.7990640027814657,0.546875 L 0.7693896384675399,0.5 L 0.6016225532830723,0.359375 L 0.3848474788416396,0.03125 L 0.34375,0.020045753913318 L 0.3157544175554352,0.046875 z M 0.3862127878137173,0.5 L 0.59375,0.520787275508311 L 0.6092715105723002,0.53125 L 0.5866609756791741,0.625 L 0.5625,0.645698910781938 L 0.40625,0.5848086265846626 L 0.3414440193218091,0.53125 L 0.3502914655341117,0.5 L 0.3862127878137173,0.5 z M 0.640625,0.5549215457503319 L 0.6848321988522705,0.5625 L 0.6575421801990426,0.625 L 0.640625,0.6293543361631952 L 0.6266403208924046,0.609375 L 0.640625,0.5549215457503319 z\" /></g></svg>"
      ],
      "text/plain": [
       "<POLYGON ((0.316 0.047, 0.305 0.094, 0.344 0.182, 0.378 0.219, 0.413 0.297, ...>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.vectorizer import num_points_from_wkt, recursive_simplify\n",
    "\n",
    "recursive_simplify(64, shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"100.0\" height=\"100.0\" viewBox=\"0.19439043677659293 -0.009533715748658734 0.6399719015848189 0.7659444873102134\" preserveAspectRatio=\"xMinYMin meet\"><g transform=\"matrix(1,0,0,-1,0,0.746877055812896)\"><path fill-rule=\"evenodd\" fill=\"#66cc99\" stroke=\"#555555\" stroke-width=\"0.015318889746204267\" opacity=\"0.6\" d=\"M 0.3157544175554352,0.046875 L 0.3047407820364258,0.09396005746455074 L 0.3269353235629424,0.1374963467073419 L 0.3444529556410871,0.18350403366942905 L 0.3780779603799269,0.21953616776936874 L 0.39854953264160287,0.26460869921139163 L 0.4212868374375562,0.3083000500371837 L 0.4545369700944553,0.34494848245600274 L 0.48828016410784436,0.38080182062052176 L 0.47413243581469755,0.42007903457028073 L 0.4253687509031439,0.42487235668734386 L 0.3765282496021399,0.4166419514484165 L 0.32804921996340447,0.4229174604332617 L 0.2846900328594747,0.44596819653049863 L 0.24113180094215322,0.4648696995614366 L 0.22275875112141566,0.5103790283276685 L 0.23634109654927465,0.5563534219835744 L 0.270423349567247,0.5922412327842863 L 0.3066644917891246,0.6246585112173975 L 0.3518991594561059,0.6433338445690472 L 0.39607986308243687,0.6654170410812724 L 0.4394769542951284,0.6891669772313598 L 0.4873377149584521,0.6992489897225795 L 0.5333690309986203,0.7153796897767848 L 0.5809376413762178,0.728042457216732 L 0.627968876963991,0.718174542402272 L 0.6729522156796499,0.700808195367174 L 0.7216879804506203,0.6919169328324298 L 0.7634876249880131,0.6690511641305089 L 0.7924104539225345,0.6289693598356282 L 0.8059940240165892,0.582842303187786 L 0.792392946086659,0.5360145229068892 L 0.7651153921205236,0.4947577841872665 L 0.7255380494537664,0.46534883609698685 L 0.6887286227596577,0.43220896466046893 L 0.6479759406003786,0.4041320670109208 L 0.6122018674618052,0.36993515932997867 L 0.5881167634270079,0.32760831099161564 L 0.5594781783104911,0.28746014638487066 L 0.5254297361406433,0.25155066046917957 L 0.5000330990101867,0.20920117256209894 L 0.4709093325054748,0.169128185993288 L 0.44493987776502625,0.1269791752717317 L 0.4174705381944239,0.0860494901572391 L 0.3950312643344015,0.042361661637978706 L 0.3540178795701125,0.018834598596163987 L 0.3157544175554352,0.046875 z M 0.3862127878137173,0.5 L 0.44243324131725703,0.5095696287574801 L 0.4998718507410461,0.5063640394774268 L 0.5559882243776499,0.5186108954234283 L 0.6090174899799382,0.5323676768064943 L 0.5902701497933813,0.5854396745799907 L 0.5758931786411297,0.6385631008241263 L 0.5226268265868731,0.631750069306027 L 0.4715580180618783,0.6107620750400755 L 0.4196974622045998,0.5923732064801179 L 0.373847788287071,0.5579582053501508 L 0.3403619032648453,0.5168529865171909 L 0.3862127878137173,0.5 z M 0.640625,0.5549215457503319 L 0.6809712433891072,0.5857145266399623 L 0.63383302857499,0.6229447604154646 L 0.640625,0.5549215457503319 z\" /></g></svg>"
      ],
      "text/plain": [
       "<POLYGON ((0.316 0.047, 0.305 0.094, 0.327 0.137, 0.344 0.184, 0.378 0.22, 0...>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvAE(nn.Module):\n",
    "    def __init__(self, fea_dim):\n",
    "        super().__init__()\n",
    "        self.fea_dim = fea_dim\n",
    "        self.encoder = nn.Sequential(nn.Conv1d(fea_dim, 64, kernel_size=3, padding=1, stride=2),\n",
    "                                     nn.ReLU(),\n",
    "                                     nn.Conv1d(64, 48, kernel_size=3, padding=1),\n",
    "                                     nn.ReLU(),\n",
    "                                     nn.Conv1d(48, 32, kernel_size=3, padding=1, stride=2),\n",
    "                                     nn.ReLU(),\n",
    "                                     nn.Conv1d(32, 24, kernel_size=3, padding=1),\n",
    "                                     nn.ReLU(),\n",
    "                                     nn.Conv1d(24, 12, kernel_size=3, padding=1, stride=2),\n",
    "                                     nn.Flatten(),\n",
    "                                     nn.Linear(12*8, 64))\n",
    "        \n",
    "        self.decoder = nn.Sequential(nn.ConvTranspose1d(12, 24, kernel_size=3, padding=1, stride=2, output_padding=1),\n",
    "                                     nn.ReLU(),\n",
    "                                     nn.ConvTranspose1d(24, 32, kernel_size=3, padding=1, stride=1, output_padding=0),\n",
    "                                     nn.ReLU(),\n",
    "                                     nn.ConvTranspose1d(32, 48, kernel_size=3, padding=1, stride=2, output_padding=1),\n",
    "                                     nn.ReLU(),\n",
    "                                     nn.ConvTranspose1d(48, 64, kernel_size=3, padding=1, stride=1, output_padding=0),\n",
    "                                     nn.ReLU(),\n",
    "                                     nn.ConvTranspose1d(64, fea_dim, kernel_size=3, padding=1, stride=2, output_padding=1))\n",
    "        \n",
    "        self.linear = nn.Sequential(\n",
    "            nn.Linear(64, 12*8),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.mse_loss_func = F.mse_loss\n",
    "        self.meta_loss_func = nn.CrossEntropyLoss()\n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        permuated_x = x.permute(0, 2, 1)  # Permute to (batch_size, channels, seq_len)\n",
    "        encoded = self.encoder(permuated_x)\n",
    "        # print(encoded.shape)\n",
    "        decoded = self.linear(encoded).reshape(encoded.size(0), 12, 8)\n",
    "        decoded = self.decoder(decoded)\n",
    "        decoded = decoded.permute(0, 2, 1)\n",
    "\n",
    "        coord_output = decoded[:, :, :2] # coord_output = decoded[:, :, :2]\n",
    "        meta_output1 = decoded[:, :, 2:4]\n",
    "        meta_output2 = decoded[:, :, 4:]\n",
    "        target_meta1 = torch.argmax(x[:, :, 2:4], dim=-1) # inner or outer points\n",
    "        target_meta2 = torch.argmax(x[:, :, 4:], dim=-1) # render one-hot code\n",
    "        coord_loss = self.mse_loss_func(coord_output, x[:, :, :2], reduction=\"none\")\n",
    "        coord_loss = coord_loss.sum(dim=[1, 2]).mean(dim=[0])\n",
    "        # 2 is inner or outer one-hot vocab size, 3 is render one-hot vocab size\n",
    "        meta_loss1 = self.meta_loss_func(meta_output1.contiguous().view(-1, 2), target_meta1.contiguous().view(-1))\n",
    "        meta_loss2 = self.meta_loss_func(meta_output2.contiguous().view(-1, 3), target_meta2.contiguous().view(-1))\n",
    "\n",
    "        meta_indices1 = torch.argmax(meta_output1, dim=-1)\n",
    "        meta_indices2 = torch.argmax(meta_output2, dim=-1)\n",
    "        output = torch.cat([coord_output, nn.functional.one_hot(meta_indices1, 2), nn.functional.one_hot(meta_indices2, 3)], dim=-1)\n",
    "        \n",
    "        return encoded, output, coord_loss*0.25 + (meta_loss1 + meta_loss2)*0.75\n",
    "        # return encoded, output, coord_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import cos, sin, pi\n",
    "\n",
    "def gen_wktLiteral(assignment, nclusters, minimal_points=3):\n",
    "    # target clusters get a unique shape \n",
    "    npoints = max(minimal_points, assignment+3)\n",
    "\n",
    "    # points equally distributed around origin\n",
    "    points = [np.array([nclusters * sin((2*pi*i)/npoints),\n",
    "                        nclusters * cos((2*pi*i)/npoints)])\n",
    "              for i in range(npoints)]\n",
    "\n",
    "    # randomize by rotation around center as we want the shape to matter\n",
    "    r = np.random.rand()\n",
    "    a = 2*pi*r\n",
    "    for point in points:\n",
    "        x, y = point\n",
    "        point[0] = y * sin(a) + x * cos(a)\n",
    "        point[1] = y * cos(a) - x * sin(a)\n",
    "\n",
    "    # centres equally distributed around origin to prevent location from\n",
    "    # being a signal.\n",
    "    centre_x = np.random.randn()/10\n",
    "    centre_y = np.random.randn()/10\n",
    "\n",
    "    # translate to new centres\n",
    "    for point in points:\n",
    "        x, y = point\n",
    "        point[0] = centre_x + x\n",
    "        point[1] = centre_y + y\n",
    "\n",
    "    points_str = [\"{} {}\".format(x, y) for x, y in points]\n",
    "    points_str.append(points_str[0])  # close polygon\n",
    "    return \"POLYGON ((\" +\\\n",
    "            \", \".join(points_str) +\\\n",
    "            \"))\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely import wkt\n",
    "\n",
    "def gen_float(min_value=-9e5, max_value=9e5):\n",
    "    return np.random.rand() * np.random.randint(min_value, max_value)\n",
    "\n",
    "def gen_point(min_lat=-90, max_lat=90, min_lon=-180, max_lon=180):\n",
    "    return (gen_float(min_lon, max_lon), gen_float(min_lat, max_lat))\n",
    "\n",
    "def gen_wktLiteral(min_length=15, max_length=64):\n",
    "    valid_polygon = False\n",
    "    while not valid_polygon:\n",
    "        num_points = np.random.randint(min_length, max_length)\n",
    "        points = [gen_point() for _ in range(num_points-1)]\n",
    "        points_str = [\"{} {}\".format(lon, lat) for (lon, lat) in points]\n",
    "        points_str.append(points_str[0])  # close polygon\n",
    "        wkt_str = \"POLYGON ((\" +\\\n",
    "                \", \".join(points_str) +\\\n",
    "                \"))\"\n",
    "        polygon = wkt.loads(wkt_str)\n",
    "        if polygon.is_valid:\n",
    "            valid_polygon = True\n",
    "\n",
    "    return polygon\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_wktLiteral()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"100.0\" height=\"100.0\" viewBox=\"-0.04 -0.04 1.08 1.08\" preserveAspectRatio=\"xMinYMin meet\"><g transform=\"matrix(1,0,0,-1,0,1.0)\"><path fill-rule=\"evenodd\" fill=\"#66cc99\" stroke=\"#555555\" stroke-width=\"0.0216\" opacity=\"0.6\" d=\"M 0.5983581526512003,1.0 L 0.32991601537201254,0.9152231186954406 L 0.04386201871008761,0.8128837450778605 L 0.0,0.6984749278189382 L 0.05246631865509126,0.35604128958121134 L 0.2807816654766975,0.1498695211120104 L 0.5875246091744795,0.0 L 0.799459127592128,0.15363414705770392 L 0.9311665328790613,0.36428025132634667 L 1.0,0.5056146494116677 L 0.8694873814284158,0.7789219063531603 L 0.7112348537225505,0.9746563361764703 L 0.5983581526512003,1.0 z\" /></g></svg>"
      ],
      "text/plain": [
       "<POLYGON ((0.598 1, 0.33 0.915, 0.044 0.813, 0 0.698, 0.052 0.356, 0.281 0.1...>"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from polygenerator import (\n",
    "    random_polygon,\n",
    "    random_star_shaped_polygon,\n",
    "    random_convex_polygon,\n",
    ")\n",
    "\n",
    "# this is just so that you can reproduce the same results\n",
    "# random.seed(5)\n",
    "\n",
    "polygon = random_star_shaped_polygon(num_points=32)\n",
    "polygon = random_polygon(num_points=32)\n",
    "polygon = random_convex_polygon(num_points=12)\n",
    "\n",
    "from shapely.geometry import Polygon\n",
    "\n",
    "Polygon(polygon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function random_polygon at 0x7d66901223b0>\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"100.0\" height=\"100.0\" viewBox=\"-0.04 -0.04 1.08 1.08\" preserveAspectRatio=\"xMinYMin meet\"><g transform=\"matrix(1,0,0,-1,0,1.0)\"><path fill-rule=\"evenodd\" fill=\"#66cc99\" stroke=\"#555555\" stroke-width=\"0.0216\" opacity=\"0.6\" d=\"M 0.01192949182169326,0.43825242086036176 L 0.07347508635996312,0.0 L 0.48246949765715,0.5443133729691613 L 0.5784727415309182,0.4243329680326691 L 1.0,0.8985996772411919 L 0.430766676249877,0.647029444084843 L 0.4903462909596318,0.7754083661420375 L 0.0,1.0 L 0.01192949182169326,0.43825242086036176 z\" /></g></svg>"
      ],
      "text/plain": [
       "<POLYGON ((0.012 0.438, 0.073 0, 0.482 0.544, 0.578 0.424, 1 0.899, 0.431 0....>"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "from shapely.geometry import Polygon\n",
    "\n",
    "# Define the list of functions and their corresponding probabilities\n",
    "functions = [random_polygon, random_star_shaped_polygon, random_convex_polygon]\n",
    "probabilities = [0.5, 0.35, 0.15]\n",
    "\n",
    "# Choose a function based on the specified probabilities\n",
    "chosen_function = random.choices(functions, weights=probabilities, k=1)[0]\n",
    "\n",
    "# Run the chosen function\n",
    "print(chosen_function)\n",
    "if chosen_function==random_polygon:\n",
    "    num_points = random.randint(3, 32)\n",
    "elif chosen_function==random_star_shaped_polygon:\n",
    "    num_points = random.randint(3, 32)\n",
    "else:\n",
    "    num_points = random.randint(3, 12)\n",
    "\n",
    "Polygon(chosen_function(num_points))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_a4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

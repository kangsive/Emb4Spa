{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "class CompareModel(nn.Module):\n",
    "    def __init__(self, emb_dim, dense_size, dropout, output_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Define the layers\n",
    "        self.conv1 = nn.Conv1d(emb_dim, 32, kernel_size=5, padding=2)  # Assuming input channels=1\n",
    "        self.conv2 = nn.Conv1d(32, 64, kernel_size=5, padding=2)\n",
    "        self.maxpool = nn.MaxPool1d(kernel_size=3)\n",
    "        self.global_avgpool = nn.AdaptiveAvgPool1d(1)  # Global average pooling\n",
    "        self.dense1 = nn.Linear(64, dense_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.dense2 = nn.Linear(dense_size, output_size)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Input shape: (batch_size, seq_len, geom_vector_len)\n",
    "        # Convolutional layers\n",
    "        x = x.permute(0, 2, 1)  # Permute to (batch_size, channels, seq_len)\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.global_avgpool(x)\n",
    "        \n",
    "        # Flatten\n",
    "        x = x.view(x.size(0), -1)  # Reshape to (batch_size, num_features)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        x = self.dense1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.dense2(x)\n",
    "        \n",
    "        # No need to add softmax (already included in CrossEntropyLossFunction), otherwise it will be double softmax and converge slower\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3 0 0]\n",
      " [4 5 0 0 0]\n",
      " [6 7 8 9 0]]\n"
     ]
    }
   ],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# def pad_sequences(sequences, maxlen=None, padding='pre', truncating='pre', value=0):\n",
    "#     if maxlen is None:\n",
    "#         maxlen = max(len(seq) for seq in sequences)\n",
    "\n",
    "#     padded_sequences = []\n",
    "#     for seq in sequences:\n",
    "#         if len(seq) >= maxlen:\n",
    "#             if truncating == 'pre':\n",
    "#                 padded_seq = seq[-maxlen:]\n",
    "#             else:\n",
    "#                 padded_seq = seq[:maxlen]\n",
    "#         else:\n",
    "#             if padding == 'pre':\n",
    "#                 padded_seq = [value] * (maxlen - len(seq)) + seq\n",
    "#             else:\n",
    "#                 padded_seq = seq + [value] * (maxlen - len(seq))\n",
    "#         padded_sequences.append(padded_seq)\n",
    "    \n",
    "#     return np.array(padded_sequences)\n",
    "\n",
    "# # Example usage\n",
    "# sequences = [[1, 2, 3], [4, 5], [6, 7, 8, 9]]\n",
    "# padded_sequences = pad_sequences(sequences, maxlen=5, padding='post', value=0)\n",
    "\n",
    "# print(padded_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# train_loaded = np.load(\"archaeology_train_v8.npz\", allow_pickle=True)\n",
    "# train_geoms = train_loaded['geoms']\n",
    "# train_labels = train_loaded['feature_type']\n",
    "\n",
    "# batch_size = 32\n",
    "# dataset_size = 1000\n",
    "# train_geoms = train_geoms[:1000]\n",
    "# train_labels = train_labels[:1000]\n",
    "\n",
    "# # Normalize\n",
    "# import geom_scaler\n",
    "\n",
    "# gs = geom_scaler.scale(train_geoms)\n",
    "# train_geoms = geom_scaler.transform(train_geoms, gs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zipped = zip(train_geoms, train_labels)\n",
    "# train_input_sorted = {}\n",
    "# train_labels_sorted = {}\n",
    "\n",
    "# for geom, label in sorted(zipped, key=lambda x: len(x[0]), reverse=True):\n",
    "#     sequence_len = geom.shape[0]\n",
    "#     smallest_size_subset = sorted(train_input_sorted.keys())[0] if train_input_sorted else None\n",
    "\n",
    "#     if not smallest_size_subset:  # This is the first data point\n",
    "#         train_input_sorted[sequence_len] = [geom]\n",
    "#         train_labels_sorted[sequence_len] = [label]\n",
    "#         continue\n",
    "\n",
    "#     if sequence_len in train_input_sorted:  # the entry exists, append\n",
    "#         train_input_sorted[sequence_len].append(geom)\n",
    "#         train_labels_sorted[sequence_len].append(label)\n",
    "#         continue\n",
    "\n",
    "#     # the size subset does not exist yet\n",
    "#     # append the data to the smallest size subset if it isn't batch-sized yet\n",
    "#     if len(train_input_sorted[smallest_size_subset]) < batch_size:\n",
    "#         print(geom)\n",
    "#         geom = pad_sequences([geom], smallest_size_subset)[0]  # make it the same size as the rest in the subset\n",
    "#         train_input_sorted[smallest_size_subset].append(geom)\n",
    "#         train_labels_sorted[smallest_size_subset].append(label)\n",
    "#     else:\n",
    "#         train_input_sorted[sequence_len] = [geom]\n",
    "#         train_labels_sorted[sequence_len] = [label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "loaded = np.load(\"dataset/train_mnist_10k.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tokens, train_labels = loaded['train_tokens'][:2000], loaded['train_labels'][:2000]\n",
    "val_tokens, val_labels = loaded['train_tokens'][2000:2500], loaded['train_labels'][2000:2500]\n",
    "\n",
    "train_tokens = torch.tensor(train_tokens, dtype=torch.float32)\n",
    "val_tokens = torch.tensor(val_tokens, dtype=torch.float32)\n",
    "train_labels= torch.tensor(train_labels, dtype=torch.long)\n",
    "val_labels = torch.tensor(val_labels, dtype=torch.long)\n",
    "\n",
    "train_loader = DataLoader(TensorDataset(train_tokens, train_labels), batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(TensorDataset(val_tokens, val_labels), batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from deep_geometry import vectorizer as gv\n",
    "from deep_geometry import GeomScaler\n",
    "\n",
    "\n",
    "max_seq_len = 64\n",
    "batch_size = 32\n",
    "\n",
    "\n",
    "geom_train, geom_test, label_train, label_test = prepare_dataset_fixedsize()\n",
    "\n",
    "train_tokens = torch.tensor(geom_train, dtype=torch.float32)\n",
    "test_tokens = torch.tensor(geom_test, dtype=torch.float32)\n",
    "train_labels= torch.tensor(label_train, dtype=torch.long)\n",
    "test_labels = torch.tensor(label_test, dtype=torch.long)\n",
    "\n",
    "train_loader = DataLoader(TensorDataset(train_tokens, train_labels), batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(TensorDataset(test_tokens, test_labels), batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "USE_GPU = True if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Train Loss: 2.1119167255976845, Train Acc 0.2075, Val Loss: 1.7884896472096443, Val Acc: 0.312\n",
      "Epoch: 2, Train Loss: 1.764197618242294, Train Acc 0.324, Val Loss: 1.6949841231107712, Val Acc: 0.348\n",
      "Epoch: 3, Train Loss: 1.5976627156848, Train Acc 0.4335, Val Loss: 1.5719761848449707, Val Acc: 0.384\n",
      "Epoch: 4, Train Loss: 1.4162943401033916, Train Acc 0.5115, Val Loss: 1.2855189889669418, Val Acc: 0.548\n",
      "Epoch: 5, Train Loss: 1.2464948570917522, Train Acc 0.5755, Val Loss: 1.1826444901525974, Val Acc: 0.596\n",
      "Epoch: 6, Train Loss: 1.1342272881477597, Train Acc 0.614, Val Loss: 1.0759311467409134, Val Acc: 0.59\n",
      "Epoch: 7, Train Loss: 1.039173252052731, Train Acc 0.637, Val Loss: 0.9304827749729156, Val Acc: 0.71\n",
      "Epoch: 8, Train Loss: 0.9418075302290538, Train Acc 0.673, Val Loss: 0.8282113894820213, Val Acc: 0.756\n",
      "Epoch: 9, Train Loss: 0.8593226065711369, Train Acc 0.7055, Val Loss: 0.8122319020330906, Val Acc: 0.748\n",
      "Epoch: 10, Train Loss: 0.8060799610047114, Train Acc 0.7295, Val Loss: 0.6952751576900482, Val Acc: 0.778\n",
      "Epoch: 11, Train Loss: 0.7345127633639744, Train Acc 0.7605, Val Loss: 0.671003594994545, Val Acc: 0.798\n",
      "Epoch: 12, Train Loss: 0.6868554036768656, Train Acc 0.768, Val Loss: 0.5878814794123173, Val Acc: 0.802\n",
      "Epoch: 13, Train Loss: 0.6301095712752569, Train Acc 0.794, Val Loss: 0.5872879531234503, Val Acc: 0.816\n",
      "Epoch: 14, Train Loss: 0.6041467341165694, Train Acc 0.7955, Val Loss: 0.546323049813509, Val Acc: 0.82\n",
      "Epoch: 15, Train Loss: 0.5554694287360661, Train Acc 0.808, Val Loss: 0.5207066927105188, Val Acc: 0.828\n",
      "Epoch: 16, Train Loss: 0.5342370486921735, Train Acc 0.8255, Val Loss: 0.46768057346343994, Val Acc: 0.862\n",
      "Epoch: 17, Train Loss: 0.48050051809303346, Train Acc 0.8435, Val Loss: 0.46227871254086494, Val Acc: 0.846\n",
      "Epoch: 18, Train Loss: 0.455435052987129, Train Acc 0.847, Val Loss: 0.40969697665423155, Val Acc: 0.856\n",
      "Epoch: 19, Train Loss: 0.43319847754069735, Train Acc 0.8535, Val Loss: 0.4127790331840515, Val Acc: 0.866\n",
      "Epoch: 20, Train Loss: 0.40509614490327384, Train Acc 0.868, Val Loss: 0.43996994476765394, Val Acc: 0.88\n",
      "Epoch: 21, Train Loss: 0.37938070935862406, Train Acc 0.878, Val Loss: 0.37389015033841133, Val Acc: 0.874\n",
      "Epoch: 22, Train Loss: 0.3748025771171328, Train Acc 0.8715, Val Loss: 0.3707994157448411, Val Acc: 0.886\n",
      "Epoch: 23, Train Loss: 0.34075416234277545, Train Acc 0.882, Val Loss: 0.358854990452528, Val Acc: 0.892\n",
      "Epoch: 24, Train Loss: 0.34507637695660665, Train Acc 0.888, Val Loss: 0.32467771600931883, Val Acc: 0.902\n",
      "Epoch: 25, Train Loss: 0.31199666810414145, Train Acc 0.902, Val Loss: 0.31061945389956236, Val Acc: 0.902\n",
      "Epoch: 26, Train Loss: 0.3086810016206333, Train Acc 0.902, Val Loss: 0.35993077140301466, Val Acc: 0.882\n",
      "Epoch: 27, Train Loss: 0.2878109507617496, Train Acc 0.9105, Val Loss: 0.3083260487765074, Val Acc: 0.906\n",
      "Epoch: 28, Train Loss: 0.26726455028567997, Train Acc 0.9095, Val Loss: 0.3024811493232846, Val Acc: 0.91\n",
      "Epoch: 29, Train Loss: 0.2639438093654693, Train Acc 0.9125, Val Loss: 0.40227664541453123, Val Acc: 0.888\n",
      "Epoch: 30, Train Loss: 0.24924921191164426, Train Acc 0.923, Val Loss: 0.2792735332623124, Val Acc: 0.914\n",
      "Epoch: 31, Train Loss: 0.2340027986774369, Train Acc 0.93, Val Loss: 0.2889309753663838, Val Acc: 0.926\n",
      "Epoch: 32, Train Loss: 0.2258728768617388, Train Acc 0.9225, Val Loss: 0.3359070075675845, Val Acc: 0.886\n",
      "Epoch: 33, Train Loss: 0.20926832715197216, Train Acc 0.933, Val Loss: 0.2920025691855699, Val Acc: 0.908\n",
      "Epoch: 34, Train Loss: 0.20507159474350156, Train Acc 0.934, Val Loss: 0.3574112798087299, Val Acc: 0.882\n",
      "Epoch: 35, Train Loss: 0.20307912902226524, Train Acc 0.9395, Val Loss: 0.35899901017546654, Val Acc: 0.894\n",
      "Epoch: 36, Train Loss: 0.2102876783363403, Train Acc 0.9385, Val Loss: 0.26254829997196794, Val Acc: 0.936\n",
      "Epoch: 37, Train Loss: 0.19452395065436287, Train Acc 0.9425, Val Loss: 0.2595947212539613, Val Acc: 0.934\n",
      "Epoch: 38, Train Loss: 0.18758847809854953, Train Acc 0.9395, Val Loss: 0.2356041492894292, Val Acc: 0.936\n",
      "Epoch: 39, Train Loss: 0.1770047155164537, Train Acc 0.9415, Val Loss: 0.24683543154969811, Val Acc: 0.924\n",
      "Epoch: 40, Train Loss: 0.1763160437759426, Train Acc 0.9385, Val Loss: 0.41668695444241166, Val Acc: 0.888\n",
      "Epoch: 41, Train Loss: 0.20311633003727783, Train Acc 0.9325, Val Loss: 0.24452183581888676, Val Acc: 0.93\n",
      "Epoch: 42, Train Loss: 0.15739177202894575, Train Acc 0.95, Val Loss: 0.2694301607552916, Val Acc: 0.928\n",
      "Epoch: 43, Train Loss: 0.16174212352387488, Train Acc 0.946, Val Loss: 0.22988419560715556, Val Acc: 0.928\n",
      "Epoch: 44, Train Loss: 0.1392954427098471, Train Acc 0.958, Val Loss: 0.2510988973081112, Val Acc: 0.922\n",
      "Epoch: 45, Train Loss: 0.1494964071445995, Train Acc 0.948, Val Loss: 0.23316237516701221, Val Acc: 0.932\n",
      "Epoch: 46, Train Loss: 0.1413612154031557, Train Acc 0.9565, Val Loss: 0.2874603341333568, Val Acc: 0.92\n",
      "Epoch: 47, Train Loss: 0.1278839698504834, Train Acc 0.9575, Val Loss: 0.24284572980832309, Val Acc: 0.94\n",
      "Epoch: 48, Train Loss: 0.12027562186417598, Train Acc 0.9605, Val Loss: 0.23291703243739903, Val Acc: 0.936\n",
      "Epoch: 49, Train Loss: 0.12008118262839695, Train Acc 0.959, Val Loss: 0.23884160444140434, Val Acc: 0.924\n",
      "Epoch: 50, Train Loss: 0.1428460913991171, Train Acc 0.9485, Val Loss: 0.22631976148113608, Val Acc: 0.934\n",
      "Epoch: 51, Train Loss: 0.13011998044592993, Train Acc 0.959, Val Loss: 0.26712591061368585, Val Acc: 0.922\n",
      "Epoch: 52, Train Loss: 0.12372280672074311, Train Acc 0.964, Val Loss: 0.2358501253183931, Val Acc: 0.93\n",
      "Epoch: 53, Train Loss: 0.11280646092361873, Train Acc 0.9595, Val Loss: 0.2350854140240699, Val Acc: 0.94\n",
      "Epoch: 54, Train Loss: 0.10489282736347781, Train Acc 0.9665, Val Loss: 0.2239917223341763, Val Acc: 0.926\n",
      "Epoch: 55, Train Loss: 0.11226172417047478, Train Acc 0.967, Val Loss: 0.2607521148165688, Val Acc: 0.926\n",
      "Epoch: 56, Train Loss: 0.11066575522815424, Train Acc 0.961, Val Loss: 0.26094244176056236, Val Acc: 0.928\n",
      "Epoch: 57, Train Loss: 0.10055507042460025, Train Acc 0.969, Val Loss: 0.2218718072399497, Val Acc: 0.932\n",
      "Epoch: 58, Train Loss: 0.09562226840191418, Train Acc 0.968, Val Loss: 0.21388109866529703, Val Acc: 0.944\n",
      "Epoch: 59, Train Loss: 0.08383314097152343, Train Acc 0.976, Val Loss: 0.21143972291611135, Val Acc: 0.944\n",
      "Epoch: 60, Train Loss: 0.08338307661728726, Train Acc 0.972, Val Loss: 0.2348605403676629, Val Acc: 0.936\n",
      "Epoch: 61, Train Loss: 0.07770826608415633, Train Acc 0.977, Val Loss: 0.2110632526455447, Val Acc: 0.944\n",
      "Epoch: 62, Train Loss: 0.08536945671464007, Train Acc 0.97, Val Loss: 0.21957801602547988, Val Acc: 0.948\n",
      "Epoch: 63, Train Loss: 0.10101129689682571, Train Acc 0.967, Val Loss: 0.21739227627404034, Val Acc: 0.944\n",
      "Epoch: 64, Train Loss: 0.09076805375812072, Train Acc 0.9715, Val Loss: 0.2851376058533788, Val Acc: 0.912\n",
      "Epoch: 65, Train Loss: 0.09518557009361094, Train Acc 0.971, Val Loss: 0.22715363564202562, Val Acc: 0.948\n",
      "Epoch: 66, Train Loss: 0.08591675511487419, Train Acc 0.973, Val Loss: 0.23856917535886168, Val Acc: 0.93\n",
      "Epoch: 67, Train Loss: 0.06752108210431677, Train Acc 0.979, Val Loss: 0.24888437142362818, Val Acc: 0.936\n",
      "Epoch: 68, Train Loss: 0.06741425745366585, Train Acc 0.9805, Val Loss: 0.24790052184835076, Val Acc: 0.936\n",
      "Epoch: 69, Train Loss: 0.07899247725967258, Train Acc 0.974, Val Loss: 0.23642041278071702, Val Acc: 0.942\n",
      "Epoch: 70, Train Loss: 0.06286186247413593, Train Acc 0.9805, Val Loss: 0.2331847446039319, Val Acc: 0.928\n",
      "Epoch: 71, Train Loss: 0.07352613588233316, Train Acc 0.972, Val Loss: 0.22378328070044518, Val Acc: 0.926\n",
      "Epoch: 72, Train Loss: 0.07270379870804766, Train Acc 0.977, Val Loss: 0.3032316903118044, Val Acc: 0.934\n",
      "Epoch: 73, Train Loss: 0.07186721842588177, Train Acc 0.977, Val Loss: 0.258489036699757, Val Acc: 0.936\n",
      "Epoch: 74, Train Loss: 0.047533216993398374, Train Acc 0.9875, Val Loss: 0.2784514880622737, Val Acc: 0.936\n",
      "Epoch: 75, Train Loss: 0.05117592785418743, Train Acc 0.9845, Val Loss: 0.26642017310950905, Val Acc: 0.926\n",
      "Epoch: 76, Train Loss: 0.05150081142635336, Train Acc 0.985, Val Loss: 0.2692423758562654, Val Acc: 0.954\n",
      "Epoch: 77, Train Loss: 0.055267635681149035, Train Acc 0.9815, Val Loss: 0.2633404280641116, Val Acc: 0.94\n",
      "Epoch: 78, Train Loss: 0.05636860340804098, Train Acc 0.982, Val Loss: 0.3049480658955872, Val Acc: 0.934\n",
      "Epoch: 79, Train Loss: 0.06254465548351171, Train Acc 0.9765, Val Loss: 0.26050712645519525, Val Acc: 0.936\n",
      "Epoch: 80, Train Loss: 0.06361798156747624, Train Acc 0.9805, Val Loss: 0.24553821724839509, Val Acc: 0.938\n",
      "Epoch: 81, Train Loss: 0.06986262989304369, Train Acc 0.9735, Val Loss: 0.3139924192801118, Val Acc: 0.934\n",
      "Epoch: 82, Train Loss: 0.07484977727105456, Train Acc 0.971, Val Loss: 0.26519668399123475, Val Acc: 0.936\n",
      "Epoch: 83, Train Loss: 0.03986057349377208, Train Acc 0.989, Val Loss: 0.26683257380500436, Val Acc: 0.942\n",
      "Epoch: 84, Train Loss: 0.03743398586465489, Train Acc 0.99, Val Loss: 0.25311673525720835, Val Acc: 0.944\n",
      "Epoch: 85, Train Loss: 0.04722663674074861, Train Acc 0.9825, Val Loss: 0.2650947160436772, Val Acc: 0.936\n",
      "Epoch: 86, Train Loss: 0.04116772791178572, Train Acc 0.9875, Val Loss: 0.3052543874364346, Val Acc: 0.928\n",
      "Epoch: 87, Train Loss: 0.0431381427860331, Train Acc 0.9885, Val Loss: 0.2767327753826976, Val Acc: 0.934\n",
      "Epoch: 88, Train Loss: 0.03556352974994788, Train Acc 0.991, Val Loss: 0.2708768319571391, Val Acc: 0.946\n",
      "Epoch: 89, Train Loss: 0.03582718933282036, Train Acc 0.9885, Val Loss: 0.3008669677656144, Val Acc: 0.938\n",
      "Epoch: 90, Train Loss: 0.06215835420326108, Train Acc 0.9745, Val Loss: 0.30502931447699666, Val Acc: 0.936\n",
      "Epoch: 91, Train Loss: 0.040867353490154655, Train Acc 0.9875, Val Loss: 0.27033221954479814, Val Acc: 0.946\n",
      "Epoch: 92, Train Loss: 0.03737821092548233, Train Acc 0.991, Val Loss: 0.25502560869790614, Val Acc: 0.95\n",
      "Epoch: 93, Train Loss: 0.05612500997016295, Train Acc 0.978, Val Loss: 0.2763027159089688, Val Acc: 0.95\n",
      "Epoch: 94, Train Loss: 0.025982379758109648, Train Acc 0.993, Val Loss: 0.2519407614017837, Val Acc: 0.952\n",
      "Epoch: 95, Train Loss: 0.02830834902771231, Train Acc 0.9905, Val Loss: 0.2965695082093589, Val Acc: 0.934\n",
      "Epoch: 96, Train Loss: 0.04743887121892638, Train Acc 0.9805, Val Loss: 0.2860728882951662, Val Acc: 0.942\n",
      "Epoch: 97, Train Loss: 0.03475139580023963, Train Acc 0.989, Val Loss: 0.30408176576020196, Val Acc: 0.942\n",
      "Epoch: 98, Train Loss: 0.02418350238567366, Train Acc 0.994, Val Loss: 0.2767958000767976, Val Acc: 0.952\n",
      "Epoch: 99, Train Loss: 0.016029670649755096, Train Acc 0.998, Val Loss: 0.29168607050087303, Val Acc: 0.938\n",
      "Epoch: 100, Train Loss: 0.024292506697025918, Train Acc 0.992, Val Loss: 0.27205696726741735, Val Acc: 0.952\n",
      "Epoch: 101, Train Loss: 0.035942373194894385, Train Acc 0.991, Val Loss: 0.2781367058341857, Val Acc: 0.946\n",
      "Epoch: 102, Train Loss: 0.021587203051673158, Train Acc 0.996, Val Loss: 0.3071689924399834, Val Acc: 0.95\n",
      "Epoch: 103, Train Loss: 0.02305765273529918, Train Acc 0.994, Val Loss: 0.3057466638274491, Val Acc: 0.944\n",
      "Epoch: 104, Train Loss: 0.030363415711603704, Train Acc 0.9915, Val Loss: 0.29378869735228363, Val Acc: 0.936\n",
      "Epoch: 105, Train Loss: 0.041510309988913675, Train Acc 0.987, Val Loss: 0.34729737730231136, Val Acc: 0.93\n",
      "Epoch: 106, Train Loss: 0.04098498414913636, Train Acc 0.985, Val Loss: 0.28710452624363825, Val Acc: 0.944\n",
      "Epoch: 107, Train Loss: 0.023621662672320826, Train Acc 0.994, Val Loss: 0.34644557230058126, Val Acc: 0.94\n",
      "Epoch: 108, Train Loss: 0.020932556126296284, Train Acc 0.994, Val Loss: 0.29694869970262516, Val Acc: 0.946\n",
      "Epoch: 109, Train Loss: 0.025068712215648874, Train Acc 0.992, Val Loss: 0.3212427074322477, Val Acc: 0.926\n",
      "Epoch: 110, Train Loss: 0.021386036235425208, Train Acc 0.994, Val Loss: 0.29114705696702003, Val Acc: 0.954\n",
      "Epoch: 111, Train Loss: 0.020423180691155028, Train Acc 0.995, Val Loss: 0.3190159006626345, Val Acc: 0.946\n",
      "Epoch: 112, Train Loss: 0.059393716953872217, Train Acc 0.9805, Val Loss: 0.40486189821967855, Val Acc: 0.918\n",
      "Epoch: 113, Train Loss: 0.1011738371480966, Train Acc 0.9665, Val Loss: 0.28775480668991804, Val Acc: 0.936\n",
      "Epoch: 114, Train Loss: 0.03792134478562585, Train Acc 0.9865, Val Loss: 0.3224744967883453, Val Acc: 0.944\n",
      "Epoch: 115, Train Loss: 0.018551802435438962, Train Acc 0.9945, Val Loss: 0.29148398456163704, Val Acc: 0.934\n",
      "Epoch: 116, Train Loss: 0.016074344909395136, Train Acc 0.9965, Val Loss: 0.29116582751157694, Val Acc: 0.948\n",
      "Epoch: 117, Train Loss: 0.009839343314293756, Train Acc 0.999, Val Loss: 0.278318427328486, Val Acc: 0.948\n",
      "Epoch: 118, Train Loss: 0.011923161728884139, Train Acc 0.9975, Val Loss: 0.30266926882904954, Val Acc: 0.944\n",
      "Epoch: 119, Train Loss: 0.019003836864915986, Train Acc 0.9955, Val Loss: 0.2927106427960098, Val Acc: 0.936\n",
      "Epoch: 120, Train Loss: 0.007573590854585674, Train Acc 0.999, Val Loss: 0.294639342231676, Val Acc: 0.948\n",
      "Epoch: 121, Train Loss: 0.0230875927823252, Train Acc 0.992, Val Loss: 0.27600024292769376, Val Acc: 0.952\n",
      "Epoch: 122, Train Loss: 0.01550492790845474, Train Acc 0.9965, Val Loss: 0.31356352230068296, Val Acc: 0.948\n",
      "Epoch: 123, Train Loss: 0.015918830818947523, Train Acc 0.997, Val Loss: 0.3320932320202701, Val Acc: 0.938\n",
      "Epoch: 124, Train Loss: 0.01894692368971716, Train Acc 0.9935, Val Loss: 0.2908839368028566, Val Acc: 0.946\n",
      "Epoch: 125, Train Loss: 0.03093225332272668, Train Acc 0.989, Val Loss: 0.5167735866270959, Val Acc: 0.904\n",
      "Epoch: 126, Train Loss: 0.03833136062455615, Train Acc 0.9875, Val Loss: 0.4049861420644447, Val Acc: 0.944\n",
      "Epoch: 127, Train Loss: 0.020399685068118813, Train Acc 0.993, Val Loss: 0.4003602982265875, Val Acc: 0.938\n",
      "Epoch: 128, Train Loss: 0.033170345415812104, Train Acc 0.989, Val Loss: 0.3828046958660707, Val Acc: 0.942\n",
      "Epoch: 129, Train Loss: 0.05890319073971893, Train Acc 0.98, Val Loss: 0.3822773753781803, Val Acc: 0.946\n",
      "Epoch: 130, Train Loss: 0.025761689162916608, Train Acc 0.992, Val Loss: 0.42793812981108204, Val Acc: 0.93\n",
      "Epoch: 131, Train Loss: 0.017720369264549975, Train Acc 0.9955, Val Loss: 0.37916584315826185, Val Acc: 0.948\n",
      "Epoch: 132, Train Loss: 0.010689072448590268, Train Acc 0.9985, Val Loss: 0.37339472118765116, Val Acc: 0.942\n",
      "Epoch: 133, Train Loss: 0.00819445300536851, Train Acc 0.9985, Val Loss: 0.39230958942789584, Val Acc: 0.942\n",
      "Epoch: 134, Train Loss: 0.005575028803644864, Train Acc 0.9995, Val Loss: 0.37173798063304275, Val Acc: 0.952\n",
      "Epoch: 135, Train Loss: 0.0042905256596563884, Train Acc 1.0, Val Loss: 0.3916412661092181, Val Acc: 0.95\n",
      "Epoch: 136, Train Loss: 0.0051699680011046845, Train Acc 0.9995, Val Loss: 0.3707251077212277, Val Acc: 0.95\n",
      "Epoch: 137, Train Loss: 0.0028163541232176597, Train Acc 1.0, Val Loss: 0.3791234501841245, Val Acc: 0.95\n",
      "Epoch: 138, Train Loss: 0.0035924834706487934, Train Acc 0.999, Val Loss: 0.38076595498569077, Val Acc: 0.948\n",
      "Epoch: 139, Train Loss: 0.0028206656550912794, Train Acc 1.0, Val Loss: 0.3756694841722492, Val Acc: 0.948\n",
      "Epoch: 140, Train Loss: 0.002441183462718664, Train Acc 1.0, Val Loss: 0.3856324895314174, Val Acc: 0.948\n",
      "Epoch: 141, Train Loss: 0.00586776084373779, Train Acc 0.999, Val Loss: 0.3889184675354045, Val Acc: 0.95\n",
      "Epoch: 142, Train Loss: 0.03441212622685328, Train Acc 0.9875, Val Loss: 0.636101447744295, Val Acc: 0.894\n",
      "Epoch: 143, Train Loss: 0.07322373227142388, Train Acc 0.977, Val Loss: 0.4059161356999539, Val Acc: 0.936\n",
      "Epoch: 144, Train Loss: 0.021243529085675995, Train Acc 0.993, Val Loss: 0.35309199543553405, Val Acc: 0.948\n",
      "Epoch: 145, Train Loss: 0.008511777994124078, Train Acc 1.0, Val Loss: 0.3647432844663854, Val Acc: 0.95\n",
      "Epoch: 146, Train Loss: 0.00677105799799652, Train Acc 0.999, Val Loss: 0.38298784013750264, Val Acc: 0.944\n",
      "Epoch: 147, Train Loss: 0.0039749195025901175, Train Acc 1.0, Val Loss: 0.37585426261648536, Val Acc: 0.952\n",
      "Epoch: 148, Train Loss: 0.0060920344574639336, Train Acc 0.9995, Val Loss: 0.37439232128235744, Val Acc: 0.952\n",
      "Epoch: 149, Train Loss: 0.011938856972385168, Train Acc 0.996, Val Loss: 0.40249634301289916, Val Acc: 0.948\n",
      "Epoch: 150, Train Loss: 0.058011856826303144, Train Acc 0.976, Val Loss: 0.4145777844823897, Val Acc: 0.938\n",
      "Epoch: 151, Train Loss: 0.02854190242480457, Train Acc 0.9905, Val Loss: 0.40997855300520314, Val Acc: 0.942\n",
      "Epoch: 152, Train Loss: 0.02792409004917043, Train Acc 0.991, Val Loss: 0.46054016950074583, Val Acc: 0.938\n",
      "Epoch: 153, Train Loss: 0.039192750773740015, Train Acc 0.9865, Val Loss: 0.3530083202640526, Val Acc: 0.95\n",
      "Epoch: 154, Train Loss: 0.018675148449902836, Train Acc 0.995, Val Loss: 0.42999053560197353, Val Acc: 0.94\n",
      "Epoch: 155, Train Loss: 0.03226904099366428, Train Acc 0.988, Val Loss: 0.39077965519391, Val Acc: 0.942\n",
      "Epoch: 156, Train Loss: 0.008593841200178889, Train Acc 0.9985, Val Loss: 0.35504004248650745, Val Acc: 0.956\n",
      "Epoch: 157, Train Loss: 0.003296615714914099, Train Acc 1.0, Val Loss: 0.35803084264625795, Val Acc: 0.954\n",
      "Epoch: 158, Train Loss: 0.002483540027502126, Train Acc 1.0, Val Loss: 0.3623346175154438, Val Acc: 0.952\n",
      "Epoch: 159, Train Loss: 0.002128210755126063, Train Acc 1.0, Val Loss: 0.3659617085068021, Val Acc: 0.95\n",
      "Epoch: 160, Train Loss: 0.003826364306333412, Train Acc 0.999, Val Loss: 0.37253035376488697, Val Acc: 0.952\n",
      "Epoch: 161, Train Loss: 0.004004924706163047, Train Acc 0.9985, Val Loss: 0.38281457903940463, Val Acc: 0.954\n",
      "Epoch: 162, Train Loss: 0.002373195440726242, Train Acc 1.0, Val Loss: 0.36932499259273754, Val Acc: 0.95\n",
      "Epoch: 163, Train Loss: 0.002411736948979235, Train Acc 0.9995, Val Loss: 0.3676713700479013, Val Acc: 0.948\n",
      "Epoch: 164, Train Loss: 0.0020193470554659143, Train Acc 1.0, Val Loss: 0.3693401364143938, Val Acc: 0.954\n",
      "Epoch: 165, Train Loss: 0.004151173255411864, Train Acc 0.9995, Val Loss: 0.3797866236054688, Val Acc: 0.948\n",
      "Epoch: 166, Train Loss: 0.0047044685904568595, Train Acc 0.9985, Val Loss: 0.374730548763182, Val Acc: 0.95\n",
      "Epoch: 167, Train Loss: 0.0013903737368338395, Train Acc 1.0, Val Loss: 0.38130306915263645, Val Acc: 0.948\n",
      "Epoch: 168, Train Loss: 0.001304371135437765, Train Acc 1.0, Val Loss: 0.38898676219105255, Val Acc: 0.95\n",
      "Epoch: 169, Train Loss: 0.0010083476820635416, Train Acc 1.0, Val Loss: 0.39177156271762215, Val Acc: 0.948\n",
      "Epoch: 170, Train Loss: 0.0009573669338438083, Train Acc 1.0, Val Loss: 0.3839721620497585, Val Acc: 0.952\n",
      "Epoch: 171, Train Loss: 0.0007607665432708075, Train Acc 1.0, Val Loss: 0.40266477627665154, Val Acc: 0.946\n",
      "Epoch: 172, Train Loss: 0.000924577321480712, Train Acc 1.0, Val Loss: 0.3888163269148208, Val Acc: 0.95\n",
      "Epoch: 173, Train Loss: 0.0010569286033777253, Train Acc 1.0, Val Loss: 0.4032954969079583, Val Acc: 0.946\n",
      "Epoch: 174, Train Loss: 0.0007741229606576131, Train Acc 1.0, Val Loss: 0.3974157822012785, Val Acc: 0.95\n",
      "Epoch: 175, Train Loss: 0.0008516272753060172, Train Acc 1.0, Val Loss: 0.3943396762624616, Val Acc: 0.95\n",
      "Epoch: 176, Train Loss: 0.0006885087005064143, Train Acc 1.0, Val Loss: 0.3996300669678021, Val Acc: 0.948\n",
      "Epoch: 177, Train Loss: 0.0006791623717227983, Train Acc 1.0, Val Loss: 0.4037833959428099, Val Acc: 0.948\n",
      "Epoch: 178, Train Loss: 0.0008614961035553799, Train Acc 1.0, Val Loss: 0.4000557498766284, Val Acc: 0.948\n",
      "Epoch: 179, Train Loss: 0.000759746056925025, Train Acc 1.0, Val Loss: 0.40000599992708885, Val Acc: 0.958\n",
      "Epoch: 180, Train Loss: 0.0005828579618652824, Train Acc 1.0, Val Loss: 0.4038773338597821, Val Acc: 0.952\n",
      "Epoch: 181, Train Loss: 0.000575310113841653, Train Acc 1.0, Val Loss: 0.41002845721232006, Val Acc: 0.952\n",
      "Epoch: 182, Train Loss: 0.0006053676646381121, Train Acc 1.0, Val Loss: 0.40737851393168967, Val Acc: 0.954\n",
      "Epoch: 183, Train Loss: 0.0014108297777027704, Train Acc 1.0, Val Loss: 0.42751610154846276, Val Acc: 0.952\n",
      "Epoch: 184, Train Loss: 0.0006031062891582094, Train Acc 1.0, Val Loss: 0.4157106650309288, Val Acc: 0.952\n",
      "Epoch: 185, Train Loss: 0.0007484827692967392, Train Acc 1.0, Val Loss: 0.43600114551372826, Val Acc: 0.946\n",
      "Epoch: 186, Train Loss: 0.0009239811371939833, Train Acc 1.0, Val Loss: 0.4268804571693181, Val Acc: 0.95\n",
      "Epoch: 187, Train Loss: 0.001080488451205181, Train Acc 1.0, Val Loss: 0.43899681365292054, Val Acc: 0.948\n",
      "Epoch: 188, Train Loss: 0.02636482324640614, Train Acc 0.9915, Val Loss: 0.5173351867124438, Val Acc: 0.918\n",
      "Epoch: 189, Train Loss: 0.15331636164115653, Train Acc 0.9495, Val Loss: 0.5973491373006254, Val Acc: 0.888\n",
      "Epoch: 190, Train Loss: 0.06440552500712257, Train Acc 0.978, Val Loss: 0.3568843246321194, Val Acc: 0.934\n",
      "Epoch: 191, Train Loss: 0.04358680758972667, Train Acc 0.985, Val Loss: 0.5024835602380335, Val Acc: 0.92\n",
      "Epoch: 192, Train Loss: 0.023753711307007406, Train Acc 0.9915, Val Loss: 0.3618704717591754, Val Acc: 0.946\n",
      "Epoch: 193, Train Loss: 0.028657352332384253, Train Acc 0.9905, Val Loss: 0.44020676310174167, Val Acc: 0.928\n",
      "Epoch: 194, Train Loss: 0.011280578611250449, Train Acc 0.9965, Val Loss: 0.3334195597890357, Val Acc: 0.948\n",
      "Epoch: 195, Train Loss: 0.002979943586517096, Train Acc 1.0, Val Loss: 0.33477323314582463, Val Acc: 0.948\n",
      "Epoch: 196, Train Loss: 0.00201307977586689, Train Acc 1.0, Val Loss: 0.3486865899321856, Val Acc: 0.948\n",
      "Epoch: 197, Train Loss: 0.0021813029815102854, Train Acc 1.0, Val Loss: 0.34256553074374096, Val Acc: 0.952\n",
      "Epoch: 198, Train Loss: 0.0012845724258878609, Train Acc 1.0, Val Loss: 0.3414333240216365, Val Acc: 0.95\n",
      "Epoch: 199, Train Loss: 0.0013271014284414594, Train Acc 1.0, Val Loss: 0.3493207096835249, Val Acc: 0.948\n",
      "Epoch: 200, Train Loss: 0.0011243950569815564, Train Acc 1.0, Val Loss: 0.3486401270420174, Val Acc: 0.944\n",
      "Epoch: 201, Train Loss: 0.0010607619712125539, Train Acc 1.0, Val Loss: 0.3534957903029863, Val Acc: 0.946\n",
      "Epoch: 202, Train Loss: 0.0009660184490683836, Train Acc 1.0, Val Loss: 0.35842147030780325, Val Acc: 0.948\n",
      "Epoch: 203, Train Loss: 0.0009730581133760371, Train Acc 1.0, Val Loss: 0.3525572872149496, Val Acc: 0.954\n",
      "Epoch: 204, Train Loss: 0.0009275486720273168, Train Acc 1.0, Val Loss: 0.3556263375157869, Val Acc: 0.946\n",
      "Epoch: 205, Train Loss: 0.0009101479075662423, Train Acc 1.0, Val Loss: 0.35897941409530176, Val Acc: 0.95\n",
      "Epoch: 206, Train Loss: 0.0008988363449264268, Train Acc 1.0, Val Loss: 0.3594746812050289, Val Acc: 0.95\n",
      "Epoch: 207, Train Loss: 0.0006988353578933692, Train Acc 1.0, Val Loss: 0.3570044096413767, Val Acc: 0.948\n",
      "Epoch: 208, Train Loss: 0.0006757098390297625, Train Acc 1.0, Val Loss: 0.3695271501219395, Val Acc: 0.952\n",
      "Epoch: 209, Train Loss: 0.0006959202766290492, Train Acc 1.0, Val Loss: 0.3670906039114925, Val Acc: 0.948\n",
      "Epoch: 210, Train Loss: 0.0005250599767769306, Train Acc 1.0, Val Loss: 0.3777907060684811, Val Acc: 0.948\n",
      "Epoch: 211, Train Loss: 0.0006053305353109156, Train Acc 1.0, Val Loss: 0.37682016128019313, Val Acc: 0.948\n",
      "Epoch: 212, Train Loss: 0.0006792847413476372, Train Acc 1.0, Val Loss: 0.38083124467812013, Val Acc: 0.948\n",
      "Epoch: 213, Train Loss: 0.000626798031185495, Train Acc 1.0, Val Loss: 0.38041653367326944, Val Acc: 0.944\n",
      "Epoch: 214, Train Loss: 0.0007326481405355495, Train Acc 1.0, Val Loss: 0.37956803410816065, Val Acc: 0.948\n",
      "Epoch: 215, Train Loss: 0.00049549844646078, Train Acc 1.0, Val Loss: 0.37796623408212326, Val Acc: 0.948\n",
      "Epoch: 216, Train Loss: 0.0004564311475116974, Train Acc 1.0, Val Loss: 0.3833628596039489, Val Acc: 0.944\n",
      "Epoch: 217, Train Loss: 0.0004950598030850487, Train Acc 1.0, Val Loss: 0.38596339709329186, Val Acc: 0.948\n",
      "Epoch: 218, Train Loss: 0.0004199831320932837, Train Acc 1.0, Val Loss: 0.39025433675851673, Val Acc: 0.95\n",
      "Epoch: 219, Train Loss: 0.0005467360516911232, Train Acc 1.0, Val Loss: 0.3867478963366011, Val Acc: 0.948\n",
      "Epoch: 220, Train Loss: 0.0004584679950528967, Train Acc 1.0, Val Loss: 0.39159980996009836, Val Acc: 0.946\n",
      "Epoch: 221, Train Loss: 0.0006768803144777415, Train Acc 1.0, Val Loss: 0.40080197864881484, Val Acc: 0.952\n",
      "Epoch: 222, Train Loss: 0.00046299134832917757, Train Acc 1.0, Val Loss: 0.4030971339016105, Val Acc: 0.946\n",
      "Epoch: 223, Train Loss: 0.0018407711523607197, Train Acc 1.0, Val Loss: 0.40684905641683144, Val Acc: 0.948\n",
      "Epoch: 224, Train Loss: 0.1622160032104783, Train Acc 0.9555, Val Loss: 0.5456684241071343, Val Acc: 0.904\n",
      "Epoch: 225, Train Loss: 0.1058164151525864, Train Acc 0.966, Val Loss: 0.47254800086375326, Val Acc: 0.934\n",
      "Epoch: 226, Train Loss: 0.05385276305374675, Train Acc 0.981, Val Loss: 0.43652660108637065, Val Acc: 0.946\n",
      "Epoch: 227, Train Loss: 0.016833712713190518, Train Acc 0.994, Val Loss: 0.4427220524230506, Val Acc: 0.946\n",
      "Epoch: 228, Train Loss: 0.005047398123664722, Train Acc 1.0, Val Loss: 0.4553760861599585, Val Acc: 0.952\n",
      "Epoch: 229, Train Loss: 0.003953468324551877, Train Acc 0.9995, Val Loss: 0.43538441954297014, Val Acc: 0.954\n",
      "Epoch: 230, Train Loss: 0.0034321293374338733, Train Acc 1.0, Val Loss: 0.44421971934934845, Val Acc: 0.958\n",
      "Epoch: 231, Train Loss: 0.0026993198566959194, Train Acc 1.0, Val Loss: 0.44184445042628795, Val Acc: 0.948\n",
      "Epoch: 232, Train Loss: 0.0017718526198425228, Train Acc 1.0, Val Loss: 0.4572338887519436, Val Acc: 0.946\n",
      "Epoch: 233, Train Loss: 0.001641677795897334, Train Acc 1.0, Val Loss: 0.4470844315728755, Val Acc: 0.95\n",
      "Epoch: 234, Train Loss: 0.0012715171770463394, Train Acc 1.0, Val Loss: 0.4513223125541117, Val Acc: 0.952\n",
      "Epoch: 235, Train Loss: 0.00172995394423774, Train Acc 1.0, Val Loss: 0.479899366344398, Val Acc: 0.944\n",
      "Epoch: 236, Train Loss: 0.0016415137140448057, Train Acc 1.0, Val Loss: 0.46352717826812295, Val Acc: 0.952\n",
      "Epoch: 237, Train Loss: 0.0010221436956877976, Train Acc 1.0, Val Loss: 0.46616080701642204, Val Acc: 0.948\n",
      "Epoch: 238, Train Loss: 0.0007936832146711707, Train Acc 1.0, Val Loss: 0.46578236209643364, Val Acc: 0.948\n",
      "Epoch: 239, Train Loss: 0.0009547450897535162, Train Acc 1.0, Val Loss: 0.46521047110582003, Val Acc: 0.948\n",
      "Epoch: 240, Train Loss: 0.0034456864516306225, Train Acc 0.999, Val Loss: 0.46848181122913957, Val Acc: 0.954\n",
      "Epoch: 241, Train Loss: 0.018831468663847772, Train Acc 0.9945, Val Loss: 0.7277529744897038, Val Acc: 0.904\n",
      "Epoch: 242, Train Loss: 0.07805557229873976, Train Acc 0.9745, Val Loss: 0.4833965397410793, Val Acc: 0.93\n",
      "Epoch: 243, Train Loss: 0.013083572285102001, Train Acc 0.9965, Val Loss: 0.3969016243281658, Val Acc: 0.946\n",
      "Epoch: 244, Train Loss: 0.004667307222945734, Train Acc 0.999, Val Loss: 0.4164737334176607, Val Acc: 0.954\n",
      "Epoch: 245, Train Loss: 0.001786489397841612, Train Acc 1.0, Val Loss: 0.41045095613480953, Val Acc: 0.954\n",
      "Epoch: 246, Train Loss: 0.0014940466665263688, Train Acc 1.0, Val Loss: 0.4194051615686476, Val Acc: 0.948\n",
      "Epoch: 247, Train Loss: 0.0011546478098251908, Train Acc 1.0, Val Loss: 0.41935875422132085, Val Acc: 0.95\n",
      "Epoch: 248, Train Loss: 0.0008627402071613774, Train Acc 1.0, Val Loss: 0.42597801434021676, Val Acc: 0.956\n",
      "Epoch: 249, Train Loss: 0.0008838542741455419, Train Acc 1.0, Val Loss: 0.4351577420857211, Val Acc: 0.95\n",
      "Epoch: 250, Train Loss: 0.0008293852737234187, Train Acc 1.0, Val Loss: 0.42936194460708066, Val Acc: 0.956\n",
      "Epoch: 251, Train Loss: 0.0007076990494545224, Train Acc 1.0, Val Loss: 0.43414792431576643, Val Acc: 0.958\n",
      "Epoch: 252, Train Loss: 0.0006894321958830078, Train Acc 1.0, Val Loss: 0.43960879257065244, Val Acc: 0.954\n",
      "Epoch: 253, Train Loss: 0.0015603483802445384, Train Acc 1.0, Val Loss: 0.4473727942795449, Val Acc: 0.952\n",
      "Epoch: 254, Train Loss: 0.0006072224648036469, Train Acc 1.0, Val Loss: 0.45002624032713356, Val Acc: 0.954\n",
      "Epoch: 255, Train Loss: 0.0005484895418559308, Train Acc 1.0, Val Loss: 0.44347106947316206, Val Acc: 0.952\n",
      "Epoch: 256, Train Loss: 0.0005395682596754919, Train Acc 1.0, Val Loss: 0.4541968516241468, Val Acc: 0.952\n",
      "Epoch: 257, Train Loss: 0.0004277107172894166, Train Acc 1.0, Val Loss: 0.45064234522033075, Val Acc: 0.95\n",
      "Epoch: 258, Train Loss: 0.0003836559916967489, Train Acc 1.0, Val Loss: 0.45416578491312976, Val Acc: 0.952\n",
      "Epoch: 259, Train Loss: 0.00036976473991614064, Train Acc 1.0, Val Loss: 0.4545958156904817, Val Acc: 0.956\n",
      "Epoch: 260, Train Loss: 0.00037623571067039546, Train Acc 1.0, Val Loss: 0.45759341104167106, Val Acc: 0.954\n",
      "Epoch: 261, Train Loss: 0.0003689180554670563, Train Acc 1.0, Val Loss: 0.4541834280062176, Val Acc: 0.956\n",
      "Epoch: 262, Train Loss: 0.00034198788274345193, Train Acc 1.0, Val Loss: 0.46623996250127675, Val Acc: 0.95\n",
      "Epoch: 263, Train Loss: 0.0003520334981398524, Train Acc 1.0, Val Loss: 0.4627178597565944, Val Acc: 0.952\n",
      "Epoch: 264, Train Loss: 0.00025749358142742755, Train Acc 1.0, Val Loss: 0.47071232712914934, Val Acc: 0.95\n",
      "Epoch: 265, Train Loss: 0.0002675321723775899, Train Acc 1.0, Val Loss: 0.47199352890311275, Val Acc: 0.948\n",
      "Epoch: 266, Train Loss: 0.0003050379044517675, Train Acc 1.0, Val Loss: 0.4770187672256725, Val Acc: 0.952\n",
      "Epoch: 267, Train Loss: 0.0003096416231052163, Train Acc 1.0, Val Loss: 0.4754555891868222, Val Acc: 0.954\n",
      "Epoch: 268, Train Loss: 0.0003403166769896329, Train Acc 1.0, Val Loss: 0.475531555552152, Val Acc: 0.95\n",
      "Epoch: 269, Train Loss: 0.0002933890044091857, Train Acc 1.0, Val Loss: 0.4791807032615907, Val Acc: 0.956\n",
      "Epoch: 270, Train Loss: 0.0002834326441520788, Train Acc 1.0, Val Loss: 0.47705527918697044, Val Acc: 0.954\n",
      "Epoch: 271, Train Loss: 0.0002734364165845031, Train Acc 1.0, Val Loss: 0.48348758608699427, Val Acc: 0.95\n",
      "Epoch: 272, Train Loss: 0.00023955058243281822, Train Acc 1.0, Val Loss: 0.4842593067769485, Val Acc: 0.952\n",
      "Epoch: 273, Train Loss: 0.00024137222758074332, Train Acc 1.0, Val Loss: 0.4829119626083411, Val Acc: 0.944\n",
      "Epoch: 274, Train Loss: 0.00022872106249465898, Train Acc 1.0, Val Loss: 0.4865853443770902, Val Acc: 0.948\n",
      "Epoch: 275, Train Loss: 0.0003067814137062265, Train Acc 1.0, Val Loss: 0.48252089789821184, Val Acc: 0.946\n",
      "Epoch: 276, Train Loss: 0.00025604949440180677, Train Acc 1.0, Val Loss: 0.4886754656472476, Val Acc: 0.95\n",
      "Epoch: 277, Train Loss: 0.00028311920092193526, Train Acc 1.0, Val Loss: 0.49695911541039095, Val Acc: 0.946\n",
      "Epoch: 278, Train Loss: 0.13084811469115454, Train Acc 0.9625, Val Loss: 0.506720183766447, Val Acc: 0.938\n",
      "Epoch: 279, Train Loss: 0.0918632151950742, Train Acc 0.9745, Val Loss: 0.34604655335715506, Val Acc: 0.946\n",
      "Epoch: 280, Train Loss: 0.029278093427401185, Train Acc 0.9915, Val Loss: 0.34641061787260696, Val Acc: 0.95\n",
      "Epoch: 281, Train Loss: 0.00974433849536119, Train Acc 0.9975, Val Loss: 0.3361356442401302, Val Acc: 0.954\n",
      "Epoch: 282, Train Loss: 0.0036965660707672155, Train Acc 1.0, Val Loss: 0.3442987904691108, Val Acc: 0.96\n",
      "Epoch: 283, Train Loss: 0.002590232755802202, Train Acc 1.0, Val Loss: 0.3411603732056392, Val Acc: 0.954\n",
      "Epoch: 284, Train Loss: 0.0021637018744802353, Train Acc 1.0, Val Loss: 0.35182916516350815, Val Acc: 0.956\n",
      "Epoch: 285, Train Loss: 0.0013203427915291358, Train Acc 1.0, Val Loss: 0.3511176121792232, Val Acc: 0.954\n",
      "Epoch: 286, Train Loss: 0.001099469014632863, Train Acc 1.0, Val Loss: 0.36053635053758626, Val Acc: 0.958\n",
      "Epoch: 287, Train Loss: 0.0011415016758999424, Train Acc 1.0, Val Loss: 0.3578909471507359, Val Acc: 0.958\n",
      "Epoch: 288, Train Loss: 0.0007616875395003248, Train Acc 1.0, Val Loss: 0.3624037174631667, Val Acc: 0.958\n",
      "Epoch: 289, Train Loss: 0.0007599233252380694, Train Acc 1.0, Val Loss: 0.36357949348530383, Val Acc: 0.956\n",
      "Epoch: 290, Train Loss: 0.0007092122910791427, Train Acc 1.0, Val Loss: 0.37557742985518416, Val Acc: 0.954\n",
      "Epoch: 291, Train Loss: 0.0006680313688573531, Train Acc 1.0, Val Loss: 0.37073094446714094, Val Acc: 0.954\n",
      "Epoch: 292, Train Loss: 0.0007241176410591126, Train Acc 1.0, Val Loss: 0.3759420886162843, Val Acc: 0.952\n",
      "Epoch: 293, Train Loss: 0.000601011541134323, Train Acc 1.0, Val Loss: 0.3724406099499902, Val Acc: 0.956\n",
      "Epoch: 294, Train Loss: 0.0004752976971166578, Train Acc 1.0, Val Loss: 0.3734799006560934, Val Acc: 0.954\n",
      "Epoch: 295, Train Loss: 0.0004714797270560031, Train Acc 1.0, Val Loss: 0.38304615093875327, Val Acc: 0.954\n",
      "Epoch: 296, Train Loss: 0.000526706456011674, Train Acc 1.0, Val Loss: 0.3825843776266993, Val Acc: 0.952\n",
      "Epoch: 297, Train Loss: 0.00047677863822461825, Train Acc 1.0, Val Loss: 0.38072317820842727, Val Acc: 0.956\n",
      "Epoch: 298, Train Loss: 0.00037162008440703623, Train Acc 1.0, Val Loss: 0.3831801051819639, Val Acc: 0.954\n",
      "Epoch: 299, Train Loss: 0.0003547290962160332, Train Acc 1.0, Val Loss: 0.388028854957156, Val Acc: 0.956\n",
      "Epoch: 300, Train Loss: 0.0003988767176119764, Train Acc 1.0, Val Loss: 0.39168081086245365, Val Acc: 0.956\n",
      "Epoch: 301, Train Loss: 0.07102447110484054, Train Acc 0.9795, Val Loss: 0.41073301560390973, Val Acc: 0.946\n",
      "Epoch: 302, Train Loss: 0.06141787212543441, Train Acc 0.975, Val Loss: 0.37285119929583743, Val Acc: 0.934\n",
      "Epoch: 303, Train Loss: 0.012204701407412474, Train Acc 0.996, Val Loss: 0.39135527073813137, Val Acc: 0.95\n",
      "Epoch: 304, Train Loss: 0.0037351981970012217, Train Acc 1.0, Val Loss: 0.36595299883629195, Val Acc: 0.952\n",
      "Epoch: 305, Train Loss: 0.0018425934302661242, Train Acc 1.0, Val Loss: 0.37097836514294613, Val Acc: 0.952\n",
      "Epoch: 306, Train Loss: 0.0010571465161139338, Train Acc 1.0, Val Loss: 0.37161643026047386, Val Acc: 0.956\n",
      "Epoch: 307, Train Loss: 0.0008921708467246462, Train Acc 1.0, Val Loss: 0.38355736252560746, Val Acc: 0.952\n",
      "Epoch: 308, Train Loss: 0.0007561912151152409, Train Acc 1.0, Val Loss: 0.38308246927772416, Val Acc: 0.954\n",
      "Epoch: 309, Train Loss: 0.0006515753281876511, Train Acc 1.0, Val Loss: 0.37968068755435525, Val Acc: 0.958\n",
      "Epoch: 310, Train Loss: 0.0007595086080116397, Train Acc 1.0, Val Loss: 0.3872820188953483, Val Acc: 0.958\n",
      "Epoch: 311, Train Loss: 0.0006498490501331934, Train Acc 1.0, Val Loss: 0.3877495009583072, Val Acc: 0.958\n",
      "Epoch: 312, Train Loss: 0.0005099455872642999, Train Acc 1.0, Val Loss: 0.3934602947483654, Val Acc: 0.958\n",
      "Epoch: 313, Train Loss: 0.0004112986173692791, Train Acc 1.0, Val Loss: 0.39100287573819514, Val Acc: 0.958\n",
      "Epoch: 314, Train Loss: 0.0004220957385509142, Train Acc 1.0, Val Loss: 0.39329283192637376, Val Acc: 0.958\n",
      "Epoch: 315, Train Loss: 0.00038592704521082824, Train Acc 1.0, Val Loss: 0.39728861789626535, Val Acc: 0.958\n",
      "Epoch: 316, Train Loss: 0.0003682703207319026, Train Acc 1.0, Val Loss: 0.3996092737725121, Val Acc: 0.958\n",
      "Epoch: 317, Train Loss: 0.00036970945118463573, Train Acc 1.0, Val Loss: 0.39929604993085377, Val Acc: 0.958\n",
      "Epoch: 318, Train Loss: 0.000359172990202852, Train Acc 1.0, Val Loss: 0.4005185545029235, Val Acc: 0.958\n",
      "Epoch: 319, Train Loss: 0.00027662700602608284, Train Acc 1.0, Val Loss: 0.40455766195373144, Val Acc: 0.958\n",
      "Epoch: 320, Train Loss: 0.00029405166858648753, Train Acc 1.0, Val Loss: 0.4104657433272223, Val Acc: 0.956\n",
      "Epoch: 321, Train Loss: 0.00027619844706985907, Train Acc 1.0, Val Loss: 0.41159180348040536, Val Acc: 0.956\n",
      "Epoch: 322, Train Loss: 0.0002442906703898131, Train Acc 1.0, Val Loss: 0.41410445937071927, Val Acc: 0.958\n",
      "Epoch: 323, Train Loss: 0.0002758551461247696, Train Acc 1.0, Val Loss: 0.41070830628086696, Val Acc: 0.958\n",
      "Epoch: 324, Train Loss: 0.00024327678493281138, Train Acc 1.0, Val Loss: 0.4116913362086052, Val Acc: 0.958\n",
      "Epoch: 325, Train Loss: 0.00020334577040182286, Train Acc 1.0, Val Loss: 0.4182065925342613, Val Acc: 0.956\n",
      "Epoch: 326, Train Loss: 0.00020866980724219632, Train Acc 1.0, Val Loss: 0.41462353943279595, Val Acc: 0.956\n",
      "Epoch: 327, Train Loss: 0.00019671446784380508, Train Acc 1.0, Val Loss: 0.4131296815285168, Val Acc: 0.956\n",
      "Epoch: 328, Train Loss: 0.00015529838592123096, Train Acc 1.0, Val Loss: 0.41571708993433276, Val Acc: 0.958\n",
      "Epoch: 329, Train Loss: 0.0001772061386289023, Train Acc 1.0, Val Loss: 0.4200260057550622, Val Acc: 0.956\n",
      "Epoch: 330, Train Loss: 0.00018653927893157944, Train Acc 1.0, Val Loss: 0.4147334120279993, Val Acc: 0.956\n",
      "Epoch: 331, Train Loss: 0.00021715126917700087, Train Acc 1.0, Val Loss: 0.4192051007557893, Val Acc: 0.956\n",
      "Epoch: 332, Train Loss: 0.00013563900632554635, Train Acc 1.0, Val Loss: 0.4185563235951122, Val Acc: 0.956\n",
      "Epoch: 333, Train Loss: 0.00018638953637462922, Train Acc 1.0, Val Loss: 0.4217804135314509, Val Acc: 0.958\n",
      "Epoch: 334, Train Loss: 0.00019527316414626381, Train Acc 1.0, Val Loss: 0.42180902204927406, Val Acc: 0.956\n",
      "Epoch: 335, Train Loss: 0.0002371840336352415, Train Acc 1.0, Val Loss: 0.4291227122594137, Val Acc: 0.958\n",
      "Epoch: 336, Train Loss: 0.00014923512516982137, Train Acc 1.0, Val Loss: 0.42370684771231026, Val Acc: 0.958\n",
      "Epoch: 337, Train Loss: 0.00012130764253737335, Train Acc 1.0, Val Loss: 0.4260704055377573, Val Acc: 0.958\n",
      "Epoch: 338, Train Loss: 0.00012727548111133585, Train Acc 1.0, Val Loss: 0.4298054451137432, Val Acc: 0.956\n",
      "Epoch: 339, Train Loss: 0.00011253500459797722, Train Acc 1.0, Val Loss: 0.43271121158613823, Val Acc: 0.954\n",
      "Epoch: 340, Train Loss: 0.00011711508098718089, Train Acc 1.0, Val Loss: 0.4288888477803994, Val Acc: 0.956\n",
      "Epoch: 341, Train Loss: 0.00011106035909896101, Train Acc 1.0, Val Loss: 0.42779576608154457, Val Acc: 0.956\n",
      "Epoch: 342, Train Loss: 0.00013706401820118551, Train Acc 1.0, Val Loss: 0.4340981253044447, Val Acc: 0.954\n",
      "Epoch: 343, Train Loss: 0.00010195099564462287, Train Acc 1.0, Val Loss: 0.4376023070526571, Val Acc: 0.958\n",
      "Epoch: 344, Train Loss: 0.00010963329975585645, Train Acc 1.0, Val Loss: 0.44034547980845673, Val Acc: 0.954\n",
      "Epoch: 345, Train Loss: 9.611086659513979e-05, Train Acc 1.0, Val Loss: 0.4396252357546473, Val Acc: 0.954\n",
      "Epoch: 346, Train Loss: 9.552947317893591e-05, Train Acc 1.0, Val Loss: 0.4374707613915234, Val Acc: 0.954\n",
      "Epoch: 347, Train Loss: 9.818668268197807e-05, Train Acc 1.0, Val Loss: 0.43571675549810607, Val Acc: 0.956\n",
      "Epoch: 348, Train Loss: 8.809501680605622e-05, Train Acc 1.0, Val Loss: 0.4299563505610422, Val Acc: 0.956\n",
      "Epoch: 349, Train Loss: 9.696897224409714e-05, Train Acc 1.0, Val Loss: 0.4339448390501275, Val Acc: 0.958\n",
      "Epoch: 350, Train Loss: 9.003524809529717e-05, Train Acc 1.0, Val Loss: 0.43485278136904526, Val Acc: 0.958\n",
      "Epoch: 351, Train Loss: 8.866978206487913e-05, Train Acc 1.0, Val Loss: 0.4516147007889231, Val Acc: 0.952\n",
      "Epoch: 352, Train Loss: 7.73157758535562e-05, Train Acc 1.0, Val Loss: 0.44959166824446584, Val Acc: 0.954\n",
      "Epoch: 353, Train Loss: 0.00010097275347987537, Train Acc 1.0, Val Loss: 0.4396089592391945, Val Acc: 0.956\n",
      "Epoch: 354, Train Loss: 8.439034718863003e-05, Train Acc 1.0, Val Loss: 0.4477483491791645, Val Acc: 0.956\n",
      "Epoch: 355, Train Loss: 0.0001091675484069186, Train Acc 1.0, Val Loss: 0.4568401466749492, Val Acc: 0.958\n",
      "Epoch: 356, Train Loss: 7.323502162517032e-05, Train Acc 1.0, Val Loss: 0.4526749533297334, Val Acc: 0.956\n",
      "Epoch: 357, Train Loss: 8.374417717053774e-05, Train Acc 1.0, Val Loss: 0.44864965853776084, Val Acc: 0.956\n",
      "Epoch: 358, Train Loss: 8.496969344233794e-05, Train Acc 1.0, Val Loss: 0.45111323279797944, Val Acc: 0.956\n",
      "Epoch: 359, Train Loss: 5.078946891162992e-05, Train Acc 1.0, Val Loss: 0.45042164229016635, Val Acc: 0.956\n",
      "Epoch: 360, Train Loss: 6.503466360415572e-05, Train Acc 1.0, Val Loss: 0.4568317759585625, Val Acc: 0.952\n",
      "Epoch: 361, Train Loss: 6.252730008782237e-05, Train Acc 1.0, Val Loss: 0.4537399531018309, Val Acc: 0.958\n",
      "Epoch: 362, Train Loss: 5.7032422975882786e-05, Train Acc 1.0, Val Loss: 0.4501834544580561, Val Acc: 0.954\n",
      "Epoch: 363, Train Loss: 5.18599913637748e-05, Train Acc 1.0, Val Loss: 0.45411806000765864, Val Acc: 0.954\n",
      "Epoch: 364, Train Loss: 5.708992428423251e-05, Train Acc 1.0, Val Loss: 0.4529931178772131, Val Acc: 0.958\n",
      "Epoch: 365, Train Loss: 7.694404119514989e-05, Train Acc 1.0, Val Loss: 0.47468262587017307, Val Acc: 0.954\n",
      "Epoch: 366, Train Loss: 0.0007413105671593445, Train Acc 1.0, Val Loss: 0.567644183694938, Val Acc: 0.942\n",
      "Epoch: 367, Train Loss: 0.25609763618558645, Train Acc 0.944, Val Loss: 0.43743180760066025, Val Acc: 0.926\n",
      "Epoch: 368, Train Loss: 0.05522683993977909, Train Acc 0.9795, Val Loss: 0.4112959411650081, Val Acc: 0.946\n",
      "Epoch: 369, Train Loss: 0.010670606455292612, Train Acc 0.998, Val Loss: 0.4420911969100416, Val Acc: 0.952\n",
      "Epoch: 370, Train Loss: 0.005729272492490487, Train Acc 0.9985, Val Loss: 0.41299158229958266, Val Acc: 0.956\n",
      "Epoch: 371, Train Loss: 0.0035273810882779162, Train Acc 0.9995, Val Loss: 0.4076187175796804, Val Acc: 0.956\n",
      "Epoch: 372, Train Loss: 0.002003431352528019, Train Acc 1.0, Val Loss: 0.4290080791015498, Val Acc: 0.95\n",
      "Epoch: 373, Train Loss: 0.0017548795977269211, Train Acc 1.0, Val Loss: 0.4433550974863465, Val Acc: 0.95\n",
      "Epoch: 374, Train Loss: 0.001393605585372637, Train Acc 1.0, Val Loss: 0.428548166125438, Val Acc: 0.952\n",
      "Epoch: 375, Train Loss: 0.0011377006586472918, Train Acc 1.0, Val Loss: 0.43849372634667816, Val Acc: 0.952\n",
      "Epoch: 376, Train Loss: 0.0007719832689857982, Train Acc 1.0, Val Loss: 0.4347155635718991, Val Acc: 0.958\n",
      "Epoch: 377, Train Loss: 0.0008923621927452688, Train Acc 1.0, Val Loss: 0.4341276961886251, Val Acc: 0.954\n",
      "Epoch: 378, Train Loss: 0.000783180588769028, Train Acc 1.0, Val Loss: 0.4391322345632034, Val Acc: 0.954\n",
      "Epoch: 379, Train Loss: 0.0006363572054339336, Train Acc 1.0, Val Loss: 0.4421306242556966, Val Acc: 0.956\n",
      "Epoch: 380, Train Loss: 0.0005651211804578207, Train Acc 1.0, Val Loss: 0.4390771888947711, Val Acc: 0.958\n",
      "Epoch: 381, Train Loss: 0.0005049752863770765, Train Acc 1.0, Val Loss: 0.44285673347621923, Val Acc: 0.956\n",
      "Epoch: 382, Train Loss: 0.0005853867673038853, Train Acc 1.0, Val Loss: 0.4467611220159142, Val Acc: 0.954\n",
      "Epoch: 383, Train Loss: 0.00045412235227732233, Train Acc 1.0, Val Loss: 0.4502521862689264, Val Acc: 0.954\n",
      "Epoch: 384, Train Loss: 0.0005186376361269227, Train Acc 1.0, Val Loss: 0.4464542799805713, Val Acc: 0.954\n",
      "Epoch: 385, Train Loss: 0.0004469793238968123, Train Acc 1.0, Val Loss: 0.44970450476284896, Val Acc: 0.954\n",
      "Epoch: 386, Train Loss: 0.00037165317008108854, Train Acc 1.0, Val Loss: 0.45838560267429784, Val Acc: 0.954\n",
      "Epoch: 387, Train Loss: 0.00036687047441586086, Train Acc 1.0, Val Loss: 0.45508633820736577, Val Acc: 0.956\n",
      "Epoch: 388, Train Loss: 0.00036495227825417674, Train Acc 1.0, Val Loss: 0.45979026415420776, Val Acc: 0.954\n",
      "Epoch: 389, Train Loss: 0.0003198072935490581, Train Acc 1.0, Val Loss: 0.4623138806798579, Val Acc: 0.954\n",
      "Epoch: 390, Train Loss: 0.0002728922459821675, Train Acc 1.0, Val Loss: 0.45925369781389236, Val Acc: 0.954\n",
      "Epoch: 391, Train Loss: 0.00033370077163915934, Train Acc 1.0, Val Loss: 0.4606645588619358, Val Acc: 0.954\n",
      "Epoch: 392, Train Loss: 0.0002778664451657927, Train Acc 1.0, Val Loss: 0.46536526283830426, Val Acc: 0.952\n",
      "Epoch: 393, Train Loss: 0.0002874402702333995, Train Acc 1.0, Val Loss: 0.46382109020737516, Val Acc: 0.956\n",
      "Epoch: 394, Train Loss: 0.00032704344840163283, Train Acc 1.0, Val Loss: 0.4666349487501975, Val Acc: 0.954\n",
      "Epoch: 395, Train Loss: 0.00019071359391033645, Train Acc 1.0, Val Loss: 0.46980384349922133, Val Acc: 0.952\n",
      "Epoch: 396, Train Loss: 0.0001924451807286777, Train Acc 1.0, Val Loss: 0.47045296333863007, Val Acc: 0.952\n",
      "Epoch: 397, Train Loss: 0.00029120425442092783, Train Acc 1.0, Val Loss: 0.4782090508606416, Val Acc: 0.952\n",
      "Epoch: 398, Train Loss: 0.00020279474173303386, Train Acc 1.0, Val Loss: 0.4748975106394937, Val Acc: 0.952\n",
      "Epoch: 399, Train Loss: 0.00027461570365024574, Train Acc 1.0, Val Loss: 0.48218802203052746, Val Acc: 0.954\n",
      "Epoch: 400, Train Loss: 0.0002189057456220441, Train Acc 1.0, Val Loss: 0.4801061959274193, Val Acc: 0.952\n",
      "Epoch: 401, Train Loss: 0.00016211537617242096, Train Acc 1.0, Val Loss: 0.4788489719220479, Val Acc: 0.954\n",
      "Epoch: 402, Train Loss: 0.0001907383135288015, Train Acc 1.0, Val Loss: 0.4806144518228166, Val Acc: 0.956\n",
      "Epoch: 403, Train Loss: 0.0001776089292766373, Train Acc 1.0, Val Loss: 0.4811999809098779, Val Acc: 0.956\n",
      "Epoch: 404, Train Loss: 0.000150090291992369, Train Acc 1.0, Val Loss: 0.4853567650745845, Val Acc: 0.956\n",
      "Epoch: 405, Train Loss: 0.00014362879103409508, Train Acc 1.0, Val Loss: 0.48618895343201984, Val Acc: 0.956\n",
      "Epoch: 406, Train Loss: 0.0001827630528948378, Train Acc 1.0, Val Loss: 0.4878514033190413, Val Acc: 0.954\n",
      "Epoch: 407, Train Loss: 0.00014300910391010268, Train Acc 1.0, Val Loss: 0.4913785740139929, Val Acc: 0.954\n",
      "Epoch: 408, Train Loss: 0.00024950384111810034, Train Acc 1.0, Val Loss: 0.513965266271498, Val Acc: 0.95\n",
      "Epoch: 409, Train Loss: 0.16881599780979395, Train Acc 0.959, Val Loss: 0.6369859853293747, Val Acc: 0.888\n",
      "Epoch: 410, Train Loss: 0.06726073478403989, Train Acc 0.978, Val Loss: 0.3988772495649755, Val Acc: 0.938\n",
      "Epoch: 411, Train Loss: 0.027565633410371708, Train Acc 0.992, Val Loss: 0.3684995172370691, Val Acc: 0.956\n",
      "Epoch: 412, Train Loss: 0.005520995758175443, Train Acc 0.999, Val Loss: 0.3893270455155289, Val Acc: 0.954\n",
      "Epoch: 413, Train Loss: 0.002833733772618755, Train Acc 1.0, Val Loss: 0.3889652465004474, Val Acc: 0.95\n",
      "Epoch: 414, Train Loss: 0.0013968054893969868, Train Acc 1.0, Val Loss: 0.38957105597364716, Val Acc: 0.956\n",
      "Epoch: 415, Train Loss: 0.001080537065544853, Train Acc 1.0, Val Loss: 0.39121129328850657, Val Acc: 0.956\n",
      "Epoch: 416, Train Loss: 0.0009958472047791084, Train Acc 1.0, Val Loss: 0.39349898260843474, Val Acc: 0.956\n",
      "Epoch: 417, Train Loss: 0.0008561431080211367, Train Acc 1.0, Val Loss: 0.3994119329727255, Val Acc: 0.956\n",
      "Epoch: 418, Train Loss: 0.0007432799808619108, Train Acc 1.0, Val Loss: 0.39982650093588745, Val Acc: 0.954\n",
      "Epoch: 419, Train Loss: 0.0007487316710582476, Train Acc 1.0, Val Loss: 0.40027099594590254, Val Acc: 0.956\n",
      "Epoch: 420, Train Loss: 0.0006293289947539701, Train Acc 1.0, Val Loss: 0.41396597547282, Val Acc: 0.95\n",
      "Epoch: 421, Train Loss: 0.0005801600086020439, Train Acc 1.0, Val Loss: 0.4185662419477012, Val Acc: 0.956\n",
      "Epoch: 422, Train Loss: 0.000427619902828675, Train Acc 1.0, Val Loss: 0.4130097400484374, Val Acc: 0.958\n",
      "Epoch: 423, Train Loss: 0.0005487287522440071, Train Acc 1.0, Val Loss: 0.41844611537089804, Val Acc: 0.956\n",
      "Epoch: 424, Train Loss: 0.000420778831539792, Train Acc 1.0, Val Loss: 0.4201027359304135, Val Acc: 0.956\n",
      "Epoch: 425, Train Loss: 0.0003991099021356878, Train Acc 1.0, Val Loss: 0.41806015066686086, Val Acc: 0.958\n",
      "Epoch: 426, Train Loss: 0.0003798758924757648, Train Acc 1.0, Val Loss: 0.42270904302131385, Val Acc: 0.956\n",
      "Epoch: 427, Train Loss: 0.0003107481626059217, Train Acc 1.0, Val Loss: 0.42511385076795705, Val Acc: 0.956\n",
      "Epoch: 428, Train Loss: 0.00034303857931277775, Train Acc 1.0, Val Loss: 0.42363491628930205, Val Acc: 0.956\n",
      "Epoch: 429, Train Loss: 0.0003786371182777368, Train Acc 1.0, Val Loss: 0.4247612951148767, Val Acc: 0.956\n",
      "Epoch: 430, Train Loss: 0.00029802645870418814, Train Acc 1.0, Val Loss: 0.42809586582006887, Val Acc: 0.954\n",
      "Epoch: 431, Train Loss: 0.00023757727963707038, Train Acc 1.0, Val Loss: 0.4321570040374354, Val Acc: 0.954\n",
      "Epoch: 432, Train Loss: 0.00023895568636593423, Train Acc 1.0, Val Loss: 0.43534080959580024, Val Acc: 0.956\n",
      "Epoch: 433, Train Loss: 0.00025539836166451946, Train Acc 1.0, Val Loss: 0.4322079420926457, Val Acc: 0.956\n",
      "Epoch: 434, Train Loss: 0.0002270245222317744, Train Acc 1.0, Val Loss: 0.4346187524679408, Val Acc: 0.954\n",
      "Epoch: 435, Train Loss: 0.00020838146621018596, Train Acc 1.0, Val Loss: 0.4373455380737141, Val Acc: 0.956\n",
      "Epoch: 436, Train Loss: 0.0002282891531909367, Train Acc 1.0, Val Loss: 0.43725246306712506, Val Acc: 0.954\n",
      "Epoch: 437, Train Loss: 0.00019487040803834956, Train Acc 1.0, Val Loss: 0.4401457591666258, Val Acc: 0.956\n",
      "Epoch: 438, Train Loss: 0.00017687213313899794, Train Acc 1.0, Val Loss: 0.4430313995471806, Val Acc: 0.956\n",
      "Epoch: 439, Train Loss: 0.00016066046177117628, Train Acc 1.0, Val Loss: 0.44486940794740804, Val Acc: 0.956\n",
      "Epoch: 440, Train Loss: 0.00016383124767300962, Train Acc 1.0, Val Loss: 0.4493136935561779, Val Acc: 0.956\n",
      "Epoch: 441, Train Loss: 0.00013504206839974763, Train Acc 1.0, Val Loss: 0.4469305295715458, Val Acc: 0.958\n",
      "Epoch: 442, Train Loss: 0.00013932323966559673, Train Acc 1.0, Val Loss: 0.44983276709899656, Val Acc: 0.958\n",
      "Epoch: 443, Train Loss: 0.00013517813795982557, Train Acc 1.0, Val Loss: 0.4541252982453443, Val Acc: 0.956\n",
      "Epoch: 444, Train Loss: 0.00014794114595711034, Train Acc 1.0, Val Loss: 0.45866178526193835, Val Acc: 0.956\n",
      "Epoch: 445, Train Loss: 0.0001429732822738775, Train Acc 1.0, Val Loss: 0.45567048341035843, Val Acc: 0.956\n",
      "Epoch: 446, Train Loss: 0.00015394375276671433, Train Acc 1.0, Val Loss: 0.44905532689517713, Val Acc: 0.956\n",
      "Epoch: 447, Train Loss: 0.0001228711937131713, Train Acc 1.0, Val Loss: 0.45655834669742035, Val Acc: 0.954\n",
      "Epoch: 448, Train Loss: 0.0001232905198040022, Train Acc 1.0, Val Loss: 0.46664486597364885, Val Acc: 0.954\n",
      "Epoch: 449, Train Loss: 0.00011243886405325265, Train Acc 1.0, Val Loss: 0.46135479398435564, Val Acc: 0.956\n",
      "Epoch: 450, Train Loss: 0.00011853836737813369, Train Acc 1.0, Val Loss: 0.4627012063683651, Val Acc: 0.956\n",
      "Epoch: 451, Train Loss: 0.0001514368546806855, Train Acc 1.0, Val Loss: 0.46377335528814, Val Acc: 0.956\n",
      "Epoch: 452, Train Loss: 9.624149475308109e-05, Train Acc 1.0, Val Loss: 0.46649987316232, Val Acc: 0.958\n",
      "Epoch: 453, Train Loss: 0.00011458640295723666, Train Acc 1.0, Val Loss: 0.46556624714139616, Val Acc: 0.956\n",
      "Epoch: 454, Train Loss: 8.746977390555479e-05, Train Acc 1.0, Val Loss: 0.47083658329574973, Val Acc: 0.956\n",
      "Epoch: 455, Train Loss: 9.338297268330943e-05, Train Acc 1.0, Val Loss: 0.4667724998871563, Val Acc: 0.958\n",
      "Epoch: 456, Train Loss: 8.913819164306569e-05, Train Acc 1.0, Val Loss: 0.471680386675871, Val Acc: 0.954\n",
      "Epoch: 457, Train Loss: 8.190638469126757e-05, Train Acc 1.0, Val Loss: 0.4719486426547519, Val Acc: 0.954\n",
      "Epoch: 458, Train Loss: 7.558993492859863e-05, Train Acc 1.0, Val Loss: 0.47137108949391404, Val Acc: 0.958\n",
      "Epoch: 459, Train Loss: 7.118723711062644e-05, Train Acc 1.0, Val Loss: 0.47141218315664446, Val Acc: 0.956\n",
      "Epoch: 460, Train Loss: 7.35020197976516e-05, Train Acc 1.0, Val Loss: 0.4788402812118875, Val Acc: 0.95\n",
      "Epoch: 461, Train Loss: 7.78346104761156e-05, Train Acc 1.0, Val Loss: 0.4708900575315056, Val Acc: 0.954\n",
      "Epoch: 462, Train Loss: 5.0775818671975264e-05, Train Acc 1.0, Val Loss: 0.4756322257599095, Val Acc: 0.952\n",
      "Epoch: 463, Train Loss: 7.271300596007749e-05, Train Acc 1.0, Val Loss: 0.4810282153193839, Val Acc: 0.954\n",
      "Epoch: 464, Train Loss: 6.866106452113695e-05, Train Acc 1.0, Val Loss: 0.48003354981483426, Val Acc: 0.954\n",
      "Epoch: 465, Train Loss: 5.934541088699628e-05, Train Acc 1.0, Val Loss: 0.473620595104876, Val Acc: 0.956\n",
      "Epoch: 466, Train Loss: 5.650549013129392e-05, Train Acc 1.0, Val Loss: 0.48145040209237777, Val Acc: 0.956\n",
      "Epoch: 467, Train Loss: 4.9397692382374065e-05, Train Acc 1.0, Val Loss: 0.47914297709394305, Val Acc: 0.958\n",
      "Epoch: 468, Train Loss: 5.5947943673388745e-05, Train Acc 1.0, Val Loss: 0.4929493189374625, Val Acc: 0.954\n",
      "Epoch: 469, Train Loss: 5.774696041628756e-05, Train Acc 1.0, Val Loss: 0.49209742511266086, Val Acc: 0.952\n",
      "Epoch: 470, Train Loss: 4.452850728537467e-05, Train Acc 1.0, Val Loss: 0.49219606450969877, Val Acc: 0.954\n",
      "Epoch: 471, Train Loss: 4.767349876796548e-05, Train Acc 1.0, Val Loss: 0.49523096368102415, Val Acc: 0.954\n",
      "Epoch: 472, Train Loss: 6.577246579632224e-05, Train Acc 1.0, Val Loss: 0.48771081997983856, Val Acc: 0.952\n",
      "Epoch: 473, Train Loss: 5.063945112967289e-05, Train Acc 1.0, Val Loss: 0.48833000057948084, Val Acc: 0.954\n",
      "Epoch: 474, Train Loss: 4.481383295627431e-05, Train Acc 1.0, Val Loss: 0.4848037373394618, Val Acc: 0.954\n",
      "Epoch: 475, Train Loss: 4.193721907353075e-05, Train Acc 1.0, Val Loss: 0.4944780677642484, Val Acc: 0.954\n",
      "Epoch: 476, Train Loss: 4.2260894108241904e-05, Train Acc 1.0, Val Loss: 0.4919418855661206, Val Acc: 0.952\n",
      "Epoch: 477, Train Loss: 3.1251749912068284e-05, Train Acc 1.0, Val Loss: 0.49725183357259084, Val Acc: 0.954\n",
      "Epoch: 478, Train Loss: 3.317864400738501e-05, Train Acc 1.0, Val Loss: 0.501144467290942, Val Acc: 0.954\n",
      "Epoch: 479, Train Loss: 3.708112776332691e-05, Train Acc 1.0, Val Loss: 0.5072877258144217, Val Acc: 0.952\n",
      "Epoch: 480, Train Loss: 3.9218506503496584e-05, Train Acc 1.0, Val Loss: 0.501003293427857, Val Acc: 0.954\n",
      "Epoch: 481, Train Loss: 3.1743147069897125e-05, Train Acc 1.0, Val Loss: 0.5124545258222497, Val Acc: 0.952\n",
      "Epoch: 482, Train Loss: 2.9619522661411633e-05, Train Acc 1.0, Val Loss: 0.502390797912085, Val Acc: 0.956\n",
      "Epoch: 483, Train Loss: 3.375817059638812e-05, Train Acc 1.0, Val Loss: 0.5077182176746646, Val Acc: 0.954\n",
      "Epoch: 484, Train Loss: 3.007843840426479e-05, Train Acc 1.0, Val Loss: 0.5103689420357114, Val Acc: 0.954\n",
      "Epoch: 485, Train Loss: 2.8031226662957155e-05, Train Acc 1.0, Val Loss: 0.5027535817625903, Val Acc: 0.954\n",
      "Epoch: 486, Train Loss: 3.5803048539102224e-05, Train Acc 1.0, Val Loss: 0.5140204811686999, Val Acc: 0.954\n",
      "Epoch: 487, Train Loss: 5.336702940347606e-05, Train Acc 1.0, Val Loss: 0.5100673906272277, Val Acc: 0.95\n",
      "Epoch: 488, Train Loss: 3.467152361153355e-05, Train Acc 1.0, Val Loss: 0.5107563996148201, Val Acc: 0.954\n",
      "Epoch: 489, Train Loss: 1.917335417725474e-05, Train Acc 1.0, Val Loss: 0.5180362374985634, Val Acc: 0.95\n",
      "Epoch: 490, Train Loss: 5.194367741166518e-05, Train Acc 1.0, Val Loss: 0.5159663427475607, Val Acc: 0.952\n",
      "Epoch: 491, Train Loss: 0.1574648914477707, Train Acc 0.969, Val Loss: 0.5088211143302033, Val Acc: 0.932\n",
      "Epoch: 492, Train Loss: 0.07802306863503339, Train Acc 0.9735, Val Loss: 0.4000685596256517, Val Acc: 0.94\n",
      "Epoch: 493, Train Loss: 0.016238718929733813, Train Acc 0.9945, Val Loss: 0.4162865951366257, Val Acc: 0.944\n",
      "Epoch: 494, Train Loss: 0.010345793345925539, Train Acc 0.996, Val Loss: 0.4137703318556305, Val Acc: 0.942\n",
      "Epoch: 495, Train Loss: 0.004534818473551977, Train Acc 0.999, Val Loss: 0.38154905569535913, Val Acc: 0.956\n",
      "Epoch: 496, Train Loss: 0.0018748584535633055, Train Acc 1.0, Val Loss: 0.39524134300881997, Val Acc: 0.954\n",
      "Epoch: 497, Train Loss: 0.0014173024372010129, Train Acc 1.0, Val Loss: 0.40077279535034904, Val Acc: 0.948\n",
      "Epoch: 498, Train Loss: 0.0006641664316529862, Train Acc 1.0, Val Loss: 0.39690821450494695, Val Acc: 0.95\n",
      "Epoch: 499, Train Loss: 0.000748357203794137, Train Acc 1.0, Val Loss: 0.4010634031401423, Val Acc: 0.948\n",
      "Epoch: 500, Train Loss: 0.00044437392225806855, Train Acc 1.0, Val Loss: 0.40223736485131667, Val Acc: 0.948\n"
     ]
    }
   ],
   "source": [
    "# Create training data\n",
    "geom_vector_len = 7  # Assuming geom_vector_len is known\n",
    "dense_size = 1024  # Size of the dense layer\n",
    "dropout = 0.1  # Dropout rate\n",
    "num_classes = 10  # Number of output classes\n",
    "\n",
    "# Define the model, loss function, and optimizer\n",
    "conv_model = CompareModel(emb_dim=geom_vector_len, dense_size=dense_size, dropout=dropout, output_size=num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(conv_model.parameters(), lr=0.001)\n",
    "\n",
    "# Training process\n",
    "num_epochs = 500\n",
    "\n",
    "# for epoch in range(num_epochs):\n",
    "#     running_loss = 0.0\n",
    "#     for seq_len in train_input_sorted:\n",
    "#         inputs = torch.tensor(train_input_sorted[seq_len], dtype=torch.float32)\n",
    "#         labels = torch.tensor(train_labels_sorted[seq_len], dtype=torch.long)\n",
    "#         dataset = TensorDataset(inputs, labels)\n",
    "#         loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "#         for batch_x, batch_y in loader:\n",
    "#             optimizer.zero_grad()\n",
    "#             output = conv_model(batch_x)\n",
    "#             loss = criterion(output, batch_y)\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "#             # Print statistics\n",
    "#             running_loss += loss.item()\n",
    "#     print(f\"Epoch {epoch+1}, Loss: {running_loss/train_geoms.shape[0]}\")\n",
    "\n",
    "def train(model, loader):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_x, batch_y in loader:\n",
    "        if USE_GPU:\n",
    "            batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_x)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += batch_y.size(0)\n",
    "        correct += (predicted == batch_y).sum().item()\n",
    "    train_loss /= len(loader)\n",
    "    train_acc = correct / total\n",
    "    return train_loss, train_acc\n",
    "\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    eval_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_x, batch_y in loader:\n",
    "            if USE_GPU:\n",
    "                batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "            outputs = model(batch_x)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            eval_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += batch_y.size(0)\n",
    "            correct += (predicted == batch_y).sum().item()\n",
    "    eval_loss /= len(loader)\n",
    "    eval_acc = correct / total\n",
    "    return eval_loss, eval_acc\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, train_acc = train(conv_model, train_loader)\n",
    "    val_loss, val_acc = evaluate(conv_model, val_loader)\n",
    "    print(f\"Epoch: {epoch+1}, Train Loss: {train_loss}, Train Acc {train_acc}, Val Loss: {val_loss}, Val Acc: {val_acc}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_a4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

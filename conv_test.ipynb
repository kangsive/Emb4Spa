{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "class CompareModel(nn.Module):\n",
    "    def __init__(self, emb_dim, dense_size, dropout, output_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Define the layers\n",
    "        self.conv1 = nn.Conv1d(emb_dim, 32, kernel_size=5, padding=2)  # Assuming input channels=1\n",
    "        self.conv2 = nn.Conv1d(32, 64, kernel_size=5, padding=2)\n",
    "        self.maxpool = nn.MaxPool1d(kernel_size=3)\n",
    "        self.global_avgpool = nn.AdaptiveAvgPool1d(1)  # Global average pooling\n",
    "        self.dense1 = nn.Linear(64, dense_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.dense2 = nn.Linear(dense_size, output_size)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Input shape: (batch_size, seq_len, geom_vector_len)\n",
    "        # Convolutional layers\n",
    "        x = x.permute(0, 2, 1)  # Permute to (batch_size, channels, seq_len)\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.global_avgpool(x)\n",
    "        \n",
    "        # Flatten\n",
    "        x = x.view(x.size(0), -1)  # Reshape to (batch_size, num_features)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        x = self.dense1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.dense2(x)\n",
    "        \n",
    "        # No need to add softmax (already included in CrossEntropyLossFunction), otherwise it will be double softmax and converge slower\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "train_loaded = np.load(\"archaeology_train_v8.npz\", allow_pickle=True)\n",
    "train_geoms = train_loaded['geoms']\n",
    "train_labels = train_loaded['feature_type']\n",
    "\n",
    "dataset_size = 1000\n",
    "train_geoms = train_geoms[:1000]\n",
    "train_labels = train_labels[:1000]\n",
    "\n",
    "# Normalize\n",
    "import geom_scaler\n",
    "\n",
    "gs = geom_scaler.scale(train_geoms)\n",
    "train_geoms = geom_scaler.transform(train_geoms, gs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "zipped = zip(train_geoms, train_labels)\n",
    "train_input_sorted = {}\n",
    "train_labels_sorted = {}\n",
    "\n",
    "for geom, label in sorted(zipped, key=lambda x: len(x[0]), reverse=True):\n",
    "    seq_len = geom.shape[0]\n",
    "    if seq_len in train_input_sorted:\n",
    "        train_input_sorted[seq_len].append(geom)\n",
    "        train_labels_sorted[seq_len].append(label)\n",
    "    else:\n",
    "        train_input_sorted[seq_len] = [geom]\n",
    "        train_labels_sorted[seq_len] = [label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_440396/2313122069.py:21: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  inputs = torch.tensor(train_input_sorted[seq_len], dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.24168250457942486\n",
      "Epoch 2, Loss: 0.21854528646357357\n",
      "Epoch 3, Loss: 0.2042471772953868\n",
      "Epoch 4, Loss: 0.2068303344398737\n",
      "Epoch 5, Loss: 0.19663107278570532\n",
      "Epoch 6, Loss: 0.19005830293893813\n",
      "Epoch 7, Loss: 0.18144561527576297\n",
      "Epoch 8, Loss: 0.18172121848911046\n",
      "Epoch 9, Loss: 0.17903948907554149\n",
      "Epoch 10, Loss: 0.18372297078371047\n",
      "Epoch 11, Loss: 0.17875683285295962\n",
      "Epoch 12, Loss: 0.1758677265048027\n",
      "Epoch 13, Loss: 0.18768857842683792\n",
      "Epoch 14, Loss: 0.1729503243714571\n",
      "Epoch 15, Loss: 0.17895330633223056\n",
      "Epoch 16, Loss: 0.16413020990043878\n",
      "Epoch 17, Loss: 0.17462833605706693\n",
      "Epoch 18, Loss: 0.17081272372603418\n",
      "Epoch 19, Loss: 0.17014122991263866\n",
      "Epoch 20, Loss: 0.1620531058870256\n",
      "Epoch 21, Loss: 0.16939565777778626\n",
      "Epoch 22, Loss: 0.16588488138467072\n",
      "Epoch 23, Loss: 0.16204914071410895\n",
      "Epoch 24, Loss: 0.16486501970514655\n",
      "Epoch 25, Loss: 0.1608663150370121\n",
      "Epoch 26, Loss: 0.15873472491651774\n",
      "Epoch 27, Loss: 0.15681633777357637\n",
      "Epoch 28, Loss: 0.15612166936695576\n",
      "Epoch 29, Loss: 0.15962821440026165\n",
      "Epoch 30, Loss: 0.15995803311467172\n",
      "Epoch 31, Loss: 0.15563196044042707\n",
      "Epoch 32, Loss: 0.15827124146418645\n",
      "Epoch 33, Loss: 0.15948817306756974\n",
      "Epoch 34, Loss: 0.15185895976424219\n",
      "Epoch 35, Loss: 0.15191743421554565\n",
      "Epoch 36, Loss: 0.1499640343002975\n",
      "Epoch 37, Loss: 0.1503751444015652\n",
      "Epoch 38, Loss: 0.15393226539716123\n",
      "Epoch 39, Loss: 0.15575568829989062\n",
      "Epoch 40, Loss: 0.15415347753465175\n",
      "Epoch 41, Loss: 0.14943968317471445\n",
      "Epoch 42, Loss: 0.1488665238652611\n",
      "Epoch 43, Loss: 0.15436656527221204\n",
      "Epoch 44, Loss: 0.14421825550403447\n",
      "Epoch 45, Loss: 0.14807180518098176\n",
      "Epoch 46, Loss: 0.14390866654505954\n",
      "Epoch 47, Loss: 0.14533964314141484\n",
      "Epoch 48, Loss: 0.1431705498471856\n",
      "Epoch 49, Loss: 0.14141097672469913\n",
      "Epoch 50, Loss: 0.14139151684567333\n"
     ]
    }
   ],
   "source": [
    "# Create training data\n",
    "sequence_length = 10\n",
    "geom_vector_len = 5  # Assuming geom_vector_len is known\n",
    "dense_size = 64  # Size of the dense layer\n",
    "dropout = 0.5  # Dropout rate\n",
    "num_classes = 10  # Number of output classes\n",
    "batch_size = 32\n",
    "dataset_size = batch_size*50\n",
    "\n",
    "# Define the model, loss function, and optimizer\n",
    "conv_model = CompareModel(emb_dim=geom_vector_len, dense_size=dense_size, dropout=dropout, output_size=num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(conv_model.parameters(), lr=0.001)\n",
    "\n",
    "# Training process\n",
    "num_epochs = 100\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for seq_len in train_input_sorted:\n",
    "        inputs = torch.tensor(train_input_sorted[seq_len], dtype=torch.float32)\n",
    "        labels = torch.tensor(train_labels_sorted[seq_len], dtype=torch.long)\n",
    "        dataset = TensorDataset(inputs, labels)\n",
    "        loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "        for batch_x, batch_y in loader:\n",
    "            optimizer.zero_grad()\n",
    "            output = conv_model(batch_x)\n",
    "            loss = criterion(output, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # Print statistics\n",
    "            running_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}, Loss: {running_loss/train_geoms.shape[0]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_a4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
